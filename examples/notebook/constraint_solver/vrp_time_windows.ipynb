{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frankuc19/fran/blob/main/examples/notebook/constraint_solver/vrp_time_windows.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "google",
      "metadata": {
        "id": "google"
      },
      "source": [
        "##### Copyright 2025 Google LLC."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "apache",
      "metadata": {
        "id": "apache"
      },
      "source": [
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "basename",
      "metadata": {
        "id": "basename"
      },
      "source": [
        "# vrp_time_windows"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "link",
      "metadata": {
        "id": "link"
      },
      "source": [
        "<table align=\"left\">\n",
        "<td>\n",
        "<a href=\"https://colab.research.google.com/github/google/or-tools/blob/main/examples/notebook/constraint_solver/vrp_time_windows.ipynb\"><img src=\"https://raw.githubusercontent.com/google/or-tools/main/tools/colab_32px.png\"/>Run in Google Colab</a>\n",
        "</td>\n",
        "<td>\n",
        "<a href=\"https://github.com/google/or-tools/blob/main/ortools/constraint_solver/samples/vrp_time_windows.py\"><img src=\"https://raw.githubusercontent.com/google/or-tools/main/tools/github_32px.png\"/>View source on GitHub</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "doc",
      "metadata": {
        "id": "doc"
      },
      "source": [
        "First, you must install [ortools](https://pypi.org/project/ortools/) package in this colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "install",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "install",
        "outputId": "e525b69b-e951-42ae-d257-60532621143f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ortools\n",
            "  Downloading ortools-9.12.4544-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting absl-py>=2.0.0 (from ortools)\n",
            "  Downloading absl_py-2.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from ortools) (2.0.2)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ortools) (2.2.2)\n",
            "Requirement already satisfied: protobuf<5.30,>=5.29.3 in /usr/local/lib/python3.11/dist-packages (from ortools) (5.29.4)\n",
            "Requirement already satisfied: immutabledict>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from ortools) (4.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->ortools) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->ortools) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->ortools) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->ortools) (1.17.0)\n",
            "Downloading ortools-9.12.4544-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (24.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.9/24.9 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading absl_py-2.2.2-py3-none-any.whl (135 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.6/135.6 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: absl-py, ortools\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.4.0\n",
            "    Uninstalling absl-py-1.4.0:\n",
            "      Successfully uninstalled absl-py-1.4.0\n",
            "Successfully installed absl-py-2.2.2 ortools-9.12.4544\n",
            "Collecting h3\n",
            "  Downloading h3-4.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Downloading h3-4.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h3\n",
            "Successfully installed h3-4.2.2\n"
          ]
        }
      ],
      "source": [
        "%pip install ortools\n",
        "!pip install h3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "description",
      "metadata": {
        "id": "description"
      },
      "source": [
        "\n",
        "Vehicles Routing Problem (VRP) with Time Windows.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "code",
      "metadata": {
        "id": "code"
      },
      "outputs": [],
      "source": [
        "from ortools.constraint_solver import routing_enums_pb2\n",
        "from ortools.constraint_solver import pywrapcp\n",
        "\n",
        "\n",
        "\n",
        "def create_data_model():\n",
        "    \"\"\"Stores the data for the problem.\"\"\"\n",
        "    data = {}\n",
        "    data[\"time_matrix\"] = [\n",
        "        [0, 6, 9, 8, 7, 3, 6, 2, 3, 2, 6, 6, 4, 4, 5, 9, 7],\n",
        "        [6, 0, 8, 3, 2, 6, 8, 4, 8, 8, 13, 7, 5, 8, 12, 10, 14],\n",
        "        [9, 8, 0, 11, 10, 6, 3, 9, 5, 8, 4, 15, 14, 13, 9, 18, 9],\n",
        "        [8, 3, 11, 0, 1, 7, 10, 6, 10, 10, 14, 6, 7, 9, 14, 6, 16],\n",
        "        [7, 2, 10, 1, 0, 6, 9, 4, 8, 9, 13, 4, 6, 8, 12, 8, 14],\n",
        "        [3, 6, 6, 7, 6, 0, 2, 3, 2, 2, 7, 9, 7, 7, 6, 12, 8],\n",
        "        [6, 8, 3, 10, 9, 2, 0, 6, 2, 5, 4, 12, 10, 10, 6, 15, 5],\n",
        "        [2, 4, 9, 6, 4, 3, 6, 0, 4, 4, 8, 5, 4, 3, 7, 8, 10],\n",
        "        [3, 8, 5, 10, 8, 2, 2, 4, 0, 3, 4, 9, 8, 7, 3, 13, 6],\n",
        "        [2, 8, 8, 10, 9, 2, 5, 4, 3, 0, 4, 6, 5, 4, 3, 9, 5],\n",
        "        [6, 13, 4, 14, 13, 7, 4, 8, 4, 4, 0, 10, 9, 8, 4, 13, 4],\n",
        "        [6, 7, 15, 6, 4, 9, 12, 5, 9, 6, 10, 0, 1, 3, 7, 3, 10],\n",
        "        [4, 5, 14, 7, 6, 7, 10, 4, 8, 5, 9, 1, 0, 2, 6, 4, 8],\n",
        "        [4, 8, 13, 9, 8, 7, 10, 3, 7, 4, 8, 3, 2, 0, 4, 5, 6],\n",
        "        [5, 12, 9, 14, 12, 6, 6, 7, 3, 3, 4, 7, 6, 4, 0, 9, 2],\n",
        "        [9, 10, 18, 6, 8, 12, 15, 8, 13, 9, 13, 3, 4, 5, 9, 0, 9],\n",
        "        [7, 14, 9, 16, 14, 8, 5, 10, 6, 5, 4, 10, 8, 6, 2, 9, 0],\n",
        "    ]\n",
        "    data[\"time_windows\"] = [\n",
        "        (0, 5),  # depot\n",
        "        (7, 12),  # 1\n",
        "        (10, 15),  # 2\n",
        "        (16, 18),  # 3\n",
        "        (10, 13),  # 4\n",
        "        (0, 5),  # 5\n",
        "        (5, 10),  # 6\n",
        "        (0, 4),  # 7\n",
        "        (5, 10),  # 8\n",
        "        (0, 3),  # 9\n",
        "        (10, 16),  # 10\n",
        "        (10, 15),  # 11\n",
        "        (0, 5),  # 12\n",
        "        (5, 10),  # 13\n",
        "        (7, 8),  # 14\n",
        "        (10, 15),  # 15\n",
        "        (11, 15),  # 16\n",
        "    ]\n",
        "    data[\"num_vehicles\"] = 4\n",
        "    data[\"depot\"] = 0\n",
        "    return data\n",
        "\n",
        "\n",
        "def print_solution(data, manager, routing, solution):\n",
        "    \"\"\"Prints solution on console.\"\"\"\n",
        "    print(f\"Objective: {solution.ObjectiveValue()}\")\n",
        "    time_dimension = routing.GetDimensionOrDie(\"Time\")\n",
        "    total_time = 0\n",
        "    for vehicle_id in range(data[\"num_vehicles\"]):\n",
        "        if not routing.IsVehicleUsed(solution, vehicle_id):\n",
        "            continue\n",
        "        index = routing.Start(vehicle_id)\n",
        "        plan_output = f\"Route for vehicle {vehicle_id}:\\n\"\n",
        "        while not routing.IsEnd(index):\n",
        "            time_var = time_dimension.CumulVar(index)\n",
        "            plan_output += (\n",
        "                f\"{manager.IndexToNode(index)}\"\n",
        "                f\" Time({solution.Min(time_var)},{solution.Max(time_var)})\"\n",
        "                \" -> \"\n",
        "            )\n",
        "            index = solution.Value(routing.NextVar(index))\n",
        "        time_var = time_dimension.CumulVar(index)\n",
        "        plan_output += (\n",
        "            f\"{manager.IndexToNode(index)}\"\n",
        "            f\" Time({solution.Min(time_var)},{solution.Max(time_var)})\\n\"\n",
        "        )\n",
        "        plan_output += f\"Time of the route: {solution.Min(time_var)}min\\n\"\n",
        "        print(plan_output)\n",
        "        total_time += solution.Min(time_var)\n",
        "    print(f\"Total time of all routes: {total_time}min\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"Solve the VRP with time windows.\"\"\"\n",
        "    # Instantiate the data problem.\n",
        "    data = create_data_model()\n",
        "\n",
        "    # Create the routing index manager.\n",
        "    manager = pywrapcp.RoutingIndexManager(\n",
        "        len(data[\"time_matrix\"]), data[\"num_vehicles\"], data[\"depot\"]\n",
        "    )\n",
        "\n",
        "    # Create Routing Model.\n",
        "    routing = pywrapcp.RoutingModel(manager)\n",
        "\n",
        "    # Create and register a transit callback.\n",
        "    def time_callback(from_index, to_index):\n",
        "        \"\"\"Returns the travel time between the two nodes.\"\"\"\n",
        "        # Convert from routing variable Index to time matrix NodeIndex.\n",
        "        from_node = manager.IndexToNode(from_index)\n",
        "        to_node = manager.IndexToNode(to_index)\n",
        "        return data[\"time_matrix\"][from_node][to_node]\n",
        "\n",
        "    transit_callback_index = routing.RegisterTransitCallback(time_callback)\n",
        "\n",
        "    # Define cost of each arc.\n",
        "    routing.SetArcCostEvaluatorOfAllVehicles(transit_callback_index)\n",
        "\n",
        "    # Add Time Windows constraint.\n",
        "    time = \"Time\"\n",
        "    routing.AddDimension(\n",
        "        transit_callback_index,\n",
        "        30,  # allow waiting time\n",
        "        30,  # maximum time per vehicle\n",
        "        False,  # Don't force start cumul to zero.\n",
        "        time,\n",
        "    )\n",
        "    time_dimension = routing.GetDimensionOrDie(time)\n",
        "    # Add time window constraints for each location except depot.\n",
        "    for location_idx, time_window in enumerate(data[\"time_windows\"]):\n",
        "        if location_idx == data[\"depot\"]:\n",
        "            continue\n",
        "        index = manager.NodeToIndex(location_idx)\n",
        "        time_dimension.CumulVar(index).SetRange(time_window[0], time_window[1])\n",
        "    # Add time window constraints for each vehicle start node.\n",
        "    depot_idx = data[\"depot\"]\n",
        "    for vehicle_id in range(data[\"num_vehicles\"]):\n",
        "        index = routing.Start(vehicle_id)\n",
        "        time_dimension.CumulVar(index).SetRange(\n",
        "            data[\"time_windows\"][depot_idx][0], data[\"time_windows\"][depot_idx][1]\n",
        "        )\n",
        "\n",
        "    # Instantiate route start and end times to produce feasible times.\n",
        "    for i in range(data[\"num_vehicles\"]):\n",
        "        routing.AddVariableMinimizedByFinalizer(\n",
        "            time_dimension.CumulVar(routing.Start(i))\n",
        "        )\n",
        "        routing.AddVariableMinimizedByFinalizer(time_dimension.CumulVar(routing.End(i)))\n",
        "\n",
        "    # Setting first solution heuristic.\n",
        "    search_parameters = pywrapcp.DefaultRoutingSearchParameters()\n",
        "    search_parameters.first_solution_strategy = (\n",
        "        routing_enums_pb2.FirstSolutionStrategy.PATH_CHEAPEST_ARC\n",
        "    )\n",
        "\n",
        "    # Solve the problem.\n",
        "    solution = routing.SolveWithParameters(search_parameters)\n",
        "\n",
        "    # Print solution on console.\n",
        "    if solution:\n",
        "        print_solution(data, manager, routing, solution)\n",
        "\n",
        "\n",
        "main()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------------------------------------\n",
        "# Parte 1: Imports y Funciones del Script de Asignación\n",
        "# ----------------------------------------------------------\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import timedelta, datetime\n",
        "import math\n",
        "import h3 # Asegúrate de que h3 está instalado (!pip install h3)\n",
        "from tqdm import tqdm # Para la barra de progreso\n",
        "import os # Para verificar existencia de archivos\n",
        "# --- Importar para descarga en Colab ---\n",
        "try:\n",
        "    from google.colab import files\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "# -------------------------------------\n",
        "\n",
        "# (El resto de imports de OR-Tools están más abajo)\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Parte 2: Constantes y Configuraciones Globales\n",
        "# ----------------------------------------------------------\n",
        "RADIO_TIERRA_KM = 6371\n",
        "PRECISION_H3 = 3\n",
        "DEFAULT_AVG_SPEED_KMH = 40\n",
        "\n",
        "# Parámetros del Modelo (¡Ajusta según sea necesario!)\n",
        "PARAM_MAX_MOVILES = 100\n",
        "PARAM_MAX_RESERVAS_POR_MOVIL = 5\n",
        "PARAM_MAX_HORAS_POR_MOVIL = 10\n",
        "ID_COLUMN_NAME = 'job_id' # <--- ¡¡¡ VERIFICA ESTE NOMBRE !!!\n",
        "SOLVER_TIME_LIMIT_SECONDS = 60\n",
        "MAX_SLACK_MINUTES = 30\n",
        "PICKUP_WINDOW_DURATION_MINUTES = 60\n",
        "\n",
        "# Valor grande para representar infinito (en minutos)\n",
        "INF_TIME = 30 * 24 * 60\n",
        "\n",
        "# Variables globales para datos precalculados\n",
        "summary_df = pd.DataFrame()\n",
        "avg_speed_kmh = DEFAULT_AVG_SPEED_KMH\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Parte 3: Funciones de Cálculo (haversine, simulate_h3_str, ...)\n",
        "# (Se mantienen igual que en la versión anterior - omitidas aquí por brevedad)\n",
        "# ... (incluye aquí las funciones haversine, simulate_h3_str,\n",
        "#      precompute_historical_averages, get_travel_time_minutes) ...\n",
        "# COPIAR FUNCIONES DE CÁLCULO DESDE LA RESPUESTA ANTERIOR AQUÍ\n",
        "def haversine(lat1, lon1, lat2, lon2):\n",
        "    \"\"\"Calcula la distancia Haversine entre dos puntos en KM.\"\"\"\n",
        "    coords = [lat1, lon1, lat2, lon2]\n",
        "    if any(map(lambda x: pd.isna(x) or x is None, coords)):\n",
        "        return np.nan\n",
        "    try:\n",
        "        lat1, lon1, lat2, lon2 = map(np.radians, coords)\n",
        "        dlat, dlon = lat2 - lat1, lon2 - lon1\n",
        "        a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
        "        c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
        "        distance = RADIO_TIERRA_KM * c\n",
        "        return distance\n",
        "    except ValueError as e:\n",
        "        # print(f\"Error calculando haversine para {coords}: {e}\") # Descomentar para debug\n",
        "        return np.nan\n",
        "\n",
        "def simulate_h3_str(lat, lon, precision=PRECISION_H3):\n",
        "     \"\"\"Genera un ID H3 string simulado basado en lat/lon redondeados.\"\"\"\n",
        "     if pd.isna(lat) or pd.isna(lon):\n",
        "         return None\n",
        "     return f\"{round(lat, precision)}_{round(lon, precision)}\"\n",
        "\n",
        "def precompute_historical_averages(df_hist):\n",
        "    \"\"\"Calcula tiempos promedio desde datos históricos y velocidad fallback.\"\"\"\n",
        "    global summary_df, avg_speed_kmh\n",
        "    required_hist_cols = {'latrecogida', 'lonrecogida', 'latdestino', 'londestino', 'tiempoestimada'}\n",
        "    if not required_hist_cols.issubset(df_hist.columns):\n",
        "        missing = required_hist_cols - set(df_hist.columns)\n",
        "        raise ValueError(f\"El DataFrame histórico no tiene las columnas necesarias: {missing}\")\n",
        "    print(\"Limpiando datos históricos...\")\n",
        "    initial_rows = len(df_hist)\n",
        "    df_hist = df_hist.dropna(subset=list(required_hist_cols))\n",
        "    df_hist['tiempoestimada'] = pd.to_numeric(df_hist['tiempoestimada'], errors='coerce')\n",
        "    df_hist = df_hist.dropna(subset=['tiempoestimada'])\n",
        "    df_hist = df_hist[df_hist['tiempoestimada'] > 0]\n",
        "    cleaned_rows_1 = len(df_hist)\n",
        "    print(f\"  {initial_rows - cleaned_rows_1} filas eliminadas por NaNs o tiempo inválido.\")\n",
        "    if df_hist.empty:\n",
        "        # ... (manejo de error igual que antes) ...\n",
        "        print(\"Advertencia: No hay datos históricos válidos después de la limpieza inicial.\")\n",
        "        summary_df = pd.DataFrame(columns=['h3_origin', 'h3_destino', 'avg_travel_time_min'])\n",
        "        avg_speed_kmh = DEFAULT_AVG_SPEED_KMH\n",
        "        print(f\"Usando velocidad fallback por defecto: {avg_speed_kmh} km/h\")\n",
        "        return\n",
        "\n",
        "    print(\"Calculando H3 y distancias para datos históricos...\")\n",
        "    df_hist['h3_origin'] = df_hist.apply(lambda row: simulate_h3_str(row['latrecogida'], row['lonrecogida']), axis=1)\n",
        "    df_hist['h3_destino'] = df_hist.apply(lambda row: simulate_h3_str(row['latdestino'], row['londestino']), axis=1)\n",
        "    df_hist['distance_km'] = df_hist.apply(lambda row: haversine(row['latrecogida'], row['lonrecogida'], row['latdestino'], row['londestino']), axis=1)\n",
        "    df_hist = df_hist.dropna(subset=['h3_origin', 'h3_destino', 'distance_km'])\n",
        "    df_hist = df_hist[df_hist['distance_km'] > 0.01]\n",
        "    cleaned_rows_2 = len(df_hist)\n",
        "    print(f\"  {cleaned_rows_1 - cleaned_rows_2} filas eliminadas por cálculo inválido de H3/distancia.\")\n",
        "    if df_hist.empty:\n",
        "        # ... (manejo de error igual que antes) ...\n",
        "        print(\"Advertencia: No hay datos históricos válidos después de calcular H3/distancia.\")\n",
        "        summary_df = pd.DataFrame(columns=['h3_origin', 'h3_destino', 'avg_travel_time_min'])\n",
        "        avg_speed_kmh = DEFAULT_AVG_SPEED_KMH\n",
        "        print(f\"Usando velocidad fallback por defecto: {avg_speed_kmh} km/h\")\n",
        "        return\n",
        "\n",
        "    print(\"Calculando tiempos promedio agrupados por H3...\")\n",
        "    avg_times_df = df_hist.groupby(['h3_origin', 'h3_destino'], as_index=False)['tiempoestimada'].median()\n",
        "    avg_times_df.rename(columns={'tiempoestimada': 'avg_travel_time_min'}, inplace=True)\n",
        "    summary_df = avg_times_df\n",
        "    print(f\"Se calcularon promedios históricos (mediana). {len(summary_df)} pares H3 origen-destino encontrados.\")\n",
        "\n",
        "    print(\"Calculando velocidad promedio global (fallback)...\")\n",
        "    df_hist['speed_kmh'] = (df_hist['distance_km'] / df_hist['tiempoestimada']) * 60\n",
        "    df_hist_valid_speed = df_hist[(df_hist['speed_kmh'] > 1) & (df_hist['speed_kmh'] < 120)]\n",
        "    if not df_hist_valid_speed.empty:\n",
        "        avg_speed_kmh = df_hist_valid_speed['speed_kmh'].median()\n",
        "        print(f\"Velocidad promedio (mediana) calculada (fallback): {avg_speed_kmh:.2f} km/h\")\n",
        "    else:\n",
        "        avg_speed_kmh = DEFAULT_AVG_SPEED_KMH\n",
        "        print(f\"No se pudieron calcular velocidades válidas. Usando fallback por defecto: {avg_speed_kmh} km/h\")\n",
        "\n",
        "def get_travel_time_minutes(h3_origin, h3_dest, fallback_distance_km):\n",
        "    \"\"\"Obtiene el tiempo de viaje promedio en minutos entre H3. Usa fallback si no se encuentra.\"\"\"\n",
        "    if h3_origin is not None and h3_dest is not None and summary_df is not None and not summary_df.empty:\n",
        "        row = summary_df[(summary_df['h3_origin'] == h3_origin) & (summary_df['h3_destino'] == h3_dest)]\n",
        "        if not row.empty:\n",
        "            avg_time = row['avg_travel_time_min'].iloc[0]\n",
        "            if pd.notna(avg_time):\n",
        "                 return int(round(avg_time))\n",
        "    if pd.notna(fallback_distance_km) and avg_speed_kmh > 0:\n",
        "        calculated_time = (fallback_distance_km / avg_speed_kmh) * 60\n",
        "        return int(round(calculated_time))\n",
        "    return 60\n",
        "# ----------------------------------------------------------\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Parte 4: Funciones de OR-Tools y Ejecución Principal\n",
        "# ----------------------------------------------------------\n",
        "from ortools.constraint_solver import routing_enums_pb2\n",
        "from ortools.constraint_solver import pywrapcp\n",
        "\n",
        "# --- MODIFICACIÓN: print_solution ahora devuelve datos ---\n",
        "def process_and_print_solution(num_jobs, tasks, data, manager, routing, solution):\n",
        "    \"\"\"Procesa la solución, la imprime y devuelve datos estructurados.\"\"\"\n",
        "    global ID_COLUMN_NAME\n",
        "\n",
        "    print(f\"\\nObjective (Total Time): {solution.ObjectiveValue()} min\")\n",
        "    time_dimension = routing.GetDimensionOrDie(\"Time\")\n",
        "    jobs_dimension = routing.GetDimensionOrDie(\"Jobs\") # Puede ser None\n",
        "\n",
        "    solution_routes = [] # Lista para almacenar la información de cada ruta usada\n",
        "    assigned_job_node_indices = set() # Para rastrear qué trabajos se asignaron\n",
        "\n",
        "    print(\"\\n--- Routes ---\")\n",
        "    for vehicle_id in range(data[\"num_vehicles\"]):\n",
        "        if not routing.IsVehicleUsed(solution, vehicle_id):\n",
        "            continue\n",
        "\n",
        "        route_nodes_indices = []\n",
        "        route_details_list = [] # Lista de diccionarios para los detalles de esta ruta\n",
        "        index = routing.Start(vehicle_id)\n",
        "        plan_output = f\"Route for vehicle {vehicle_id}:\\n\"\n",
        "        plan_output += \"  Start (Source) -> \"\n",
        "        route_time = 0\n",
        "\n",
        "        while True:\n",
        "            node_index_internal = index\n",
        "            node_index_mapped = manager.IndexToNode(node_index_internal)\n",
        "\n",
        "            if 0 <= node_index_mapped < num_jobs: # Es un nodo de trabajo\n",
        "                job_idx = node_index_mapped\n",
        "                task_info = tasks[job_idx]\n",
        "                time_var = time_dimension.CumulVar(node_index_internal)\n",
        "                arrival_time_min = solution.Min(time_var)\n",
        "                arrival_time_max = solution.Max(time_var)\n",
        "                job_count_at_node = \"N/A\"\n",
        "                if jobs_dimension:\n",
        "                    try:\n",
        "                        jobs_var = jobs_dimension.CumulVar(node_index_internal)\n",
        "                        job_count_at_node = solution.Value(jobs_var)\n",
        "                    except Exception: pass\n",
        "\n",
        "                plan_output += (\n",
        "                    f\"Job_{task_info.get(ID_COLUMN_NAME, job_idx)}\"\n",
        "                    f\" [P:{task_info['pickup_time_str']}]\"\n",
        "                    f\" (Arr: {arrival_time_min}-{arrival_time_max} min)\"\n",
        "                    f\" (Jobs: {job_count_at_node})\"\n",
        "                    \" -> \"\n",
        "                )\n",
        "                # Guardar detalles del trabajo asignado\n",
        "                job_detail = {\n",
        "                    \"or_tools_vehicle_id\": vehicle_id, # ID interno de OR-Tools\n",
        "                    \"job_id_unique\": task_info.get(ID_COLUMN_NAME, job_idx), # El ID del trabajo\n",
        "                    \"node_index\": job_idx, # Índice 0..num_jobs-1\n",
        "                    \"pickup_time_original\": task_info['pickup_time_str'],\n",
        "                    \"arrival_minutes_min\": arrival_time_min,\n",
        "                    \"arrival_minutes_max\": arrival_time_max,\n",
        "                    \"job_count_at_node\": job_count_at_node,\n",
        "                    # Añadir otros datos relevantes de task_info si es necesario\n",
        "                    \"estimated_payment\": task_info.get('estimated_payment', 0), # Incluir pago\n",
        "                    \"pickup_lat\": task_info.get('pickup_lat'),\n",
        "                    \"pickup_lon\": task_info.get('pickup_lon'),\n",
        "                    \"dropoff_lat\": task_info.get('dropoff_lat'),\n",
        "                    \"dropoff_lon\": task_info.get('dropoff_lon'),\n",
        "                }\n",
        "                route_details_list.append(job_detail)\n",
        "                route_nodes_indices.append(job_idx)\n",
        "                assigned_job_node_indices.add(job_idx) # Marcar como asignado\n",
        "\n",
        "            if routing.IsEnd(index):\n",
        "                if node_index_mapped == data[\"sink_node\"]:\n",
        "                    time_var_end = time_dimension.CumulVar(node_index_internal)\n",
        "                    route_time = solution.Min(time_var_end)\n",
        "                    plan_output += f\"End (Sink) [Total Time: {route_time} min]\"\n",
        "                else:\n",
        "                    plan_output += f\"End (Node {node_index_mapped}?) [Incomplete Route Trace]\"\n",
        "                    route_time = solution.ObjectiveValue()\n",
        "                break\n",
        "            index = solution.Value(routing.NextVar(index))\n",
        "\n",
        "        print(plan_output)\n",
        "        print(f\"  Jobs in route: {len(route_nodes_indices)}\")\n",
        "\n",
        "        # Guardar información de la ruta completa\n",
        "        solution_routes.append({\n",
        "            \"or_tools_vehicle_id\": vehicle_id,\n",
        "            \"route_nodes\": route_nodes_indices, # Lista de índices de trabajos\n",
        "            \"route_details\": route_details_list, # Lista de detalles por trabajo\n",
        "            \"total_route_time_min\": route_time,\n",
        "            \"total_jobs_in_route\": len(route_nodes_indices)\n",
        "        })\n",
        "\n",
        "    total_jobs_assigned = len(assigned_job_node_indices)\n",
        "    print(f\"\\n--- Summary ---\")\n",
        "    print(f\"Total time of all routes: {solution.ObjectiveValue()} min\") # Usar valor objetivo para tiempo total\n",
        "    print(f\"Total jobs assigned: {total_jobs_assigned} / {num_jobs}\")\n",
        "\n",
        "    # Devolver los datos procesados\n",
        "    return solution_routes, assigned_job_node_indices, total_jobs_assigned\n",
        "# --- Fin de la función modificada ---\n",
        "\n",
        "\n",
        "def main_ortools(df_hist_path, df_pred_path):\n",
        "    \"\"\"Función principal que carga datos, configura, resuelve y exporta.\"\"\"\n",
        "    global ID_COLUMN_NAME\n",
        "\n",
        "    # 1. Cargar Datos y 2. Validar Predicciones (igual que antes)\n",
        "    print(\"Cargando archivos...\")\n",
        "    try:\n",
        "        df_hist = pd.read_csv(df_hist_path)\n",
        "        dtypes_pred = {'latrecogida': float, 'lonrecogida': float, 'latdestino': float, 'londestino': float}\n",
        "        df_pred = pd.read_csv(df_pred_path, dtype=dtypes_pred, low_memory=False)\n",
        "        print(f\"Históricos cargados: {len(df_hist)} filas\")\n",
        "        print(f\"Predicciones cargadas: {len(df_pred)} filas\")\n",
        "    except FileNotFoundError as e: print(f\"Error: No se encontró el archivo {e.filename}\"); return\n",
        "    except Exception as e: print(f\"Error cargando archivos CSV: {e}\"); return\n",
        "\n",
        "    print(\"Validando y preparando datos de predicción...\")\n",
        "    required_pred_cols = {'latrecogida', 'lonrecogida', 'latdestino', 'londestino', 'pickup_datetime', ID_COLUMN_NAME}\n",
        "    if not required_pred_cols.issubset(df_pred.columns):\n",
        "         missing_cols = required_pred_cols - set(df_pred.columns)\n",
        "         print(f\"Error: Faltan columnas requeridas en predicciones: {missing_cols}\")\n",
        "         print(f\"Columnas encontradas: {list(df_pred.columns)}\"); return\n",
        "    if 'estimated_payment' not in df_pred.columns:\n",
        "        print(\"Advertencia: Columna 'estimated_payment' no encontrada. Se usará 0.\")\n",
        "        df_pred['estimated_payment'] = 0\n",
        "    else:\n",
        "         # Asegurarse que sea numérico\n",
        "         df_pred['estimated_payment'] = pd.to_numeric(df_pred['estimated_payment'], errors='coerce').fillna(0)\n",
        "\n",
        "\n",
        "    try:\n",
        "        df_pred['HoraFecha'] = pd.to_datetime(df_pred['pickup_datetime'], errors='coerce')\n",
        "    except Exception as e: print(f\"Error convirtiendo 'pickup_datetime' a fecha: {e}\"); return\n",
        "    df_pred = df_pred.dropna(subset=['HoraFecha'])\n",
        "    if df_pred.empty: print(\"Error: No hay fechas válidas ('pickup_datetime').\"); return\n",
        "    start_horizon_time = df_pred['HoraFecha'].min()\n",
        "    print(f\"Horizonte de planificación inicia en: {start_horizon_time}\")\n",
        "\n",
        "    # 3. Precomputar Promedios (igual que antes)\n",
        "    print(\"Precalculando promedios históricos...\")\n",
        "    try: precompute_historical_averages(df_hist)\n",
        "    except ValueError as e: print(f\"Error en precomputo histórico: {e}\"); return\n",
        "    except Exception as e: print(f\"Error inesperado en precomputo histórico: {e}\"); return\n",
        "\n",
        "    # 4. Preparar Lista de Tareas (igual que antes, asegurando 'estimated_payment')\n",
        "    print(\"Preparando lista de tareas (trabajos)...\")\n",
        "    tasks = []\n",
        "    job_durations_min = []\n",
        "    pickup_coords = []\n",
        "    dropoff_coords = []\n",
        "    pickup_windows_min = []\n",
        "    skipped_jobs = 0\n",
        "    for idx, row in df_pred.iterrows():\n",
        "        required_row_data = ['latrecogida', 'lonrecogida', 'latdestino', 'londestino', 'HoraFecha']\n",
        "        if any(pd.isna(row[col]) for col in required_row_data):\n",
        "             job_id_display = row.get(ID_COLUMN_NAME, f\"index_{idx}\")\n",
        "             print(f\"Advertencia: Saltando trabajo '{job_id_display}' por datos faltantes.\")\n",
        "             skipped_jobs += 1; continue\n",
        "        h3_pickup = simulate_h3_str(row['latrecogida'], row['lonrecogida'])\n",
        "        h3_dropoff = simulate_h3_str(row['latdestino'], row['londestino'])\n",
        "        distance_job_km = haversine(row['latrecogida'], row['lonrecogida'], row['latdestino'], row['londestino'])\n",
        "        job_duration = get_travel_time_minutes(h3_pickup, h3_dropoff, distance_job_km)\n",
        "        job_durations_min.append(job_duration)\n",
        "        earliest_pickup_time = row['HoraFecha']\n",
        "        pickup_start_min = int(round((earliest_pickup_time - start_horizon_time).total_seconds() / 60))\n",
        "        pickup_end_min = pickup_start_min + PICKUP_WINDOW_DURATION_MINUTES\n",
        "        pickup_windows_min.append((max(0, pickup_start_min), pickup_end_min))\n",
        "        task_data = {\n",
        "            \"original_index\": idx,\n",
        "            ID_COLUMN_NAME : row.get(ID_COLUMN_NAME),\n",
        "            \"pickup_lat\": row['latrecogida'],\"pickup_lon\": row['lonrecogida'],\n",
        "            \"dropoff_lat\": row['latdestino'],\"dropoff_lon\": row['londestino'],\n",
        "            \"h3_pickup\": h3_pickup,\"h3_dropoff\": h3_dropoff,\n",
        "            \"pickup_time\": earliest_pickup_time,\"pickup_time_str\": earliest_pickup_time.strftime('%Y-%m-%d %H:%M'),\n",
        "            # Incluir estimated_payment en los datos de la tarea\n",
        "            \"estimated_payment\": row.get('estimated_payment', 0)\n",
        "        }\n",
        "        tasks.append(task_data)\n",
        "        pickup_coords.append((row['latrecogida'], row['lonrecogida']))\n",
        "        dropoff_coords.append((row['latdestino'], row['londestino']))\n",
        "    num_jobs = len(tasks)\n",
        "    if num_jobs == 0: print(f\"Error: No hay trabajos válidos (se saltaron {skipped_jobs}).\"); return\n",
        "    print(f\"Número de trabajos a asignar: {num_jobs} (se saltaron {skipped_jobs})\")\n",
        "\n",
        "    # 5. Configurar Nodos y Vehículos (igual que antes)\n",
        "    num_vehicles = min(PARAM_MAX_MOVILES, num_jobs)\n",
        "    print(f\"Número de vehículos a usar: {num_vehicles}\")\n",
        "    num_locations_total = num_jobs + 2\n",
        "    source_node = num_jobs\n",
        "    sink_node = num_jobs + 1\n",
        "\n",
        "    # 6. Precalcular Matriz de Tiempos (igual que antes, con tqdm)\n",
        "    print(\"Precalculando matriz de tiempos de viaje inter-trabajos...\")\n",
        "    travel_times_min = [[0] * num_jobs for _ in range(num_jobs)]\n",
        "    for i in tqdm(range(num_jobs), desc=\"Calculando Matriz Tiempos\", unit=\"job\"):\n",
        "        for j in range(num_jobs):\n",
        "            if i == j: travel_times_min[i][j] = INF_TIME; continue\n",
        "            lat1, lon1 = dropoff_coords[i]; lat2, lon2 = pickup_coords[j]\n",
        "            h3_origin = tasks[i][\"h3_dropoff\"]; h3_dest = tasks[j][\"h3_pickup\"]\n",
        "            distance_km_fallback = haversine(lat1, lon1, lat2, lon2)\n",
        "            travel_times_min[i][j] = get_travel_time_minutes(h3_origin, h3_dest, distance_km_fallback)\n",
        "    print(\"Matriz de tiempos inter-trabajos calculada.\")\n",
        "\n",
        "    # 7. Crear Manager y Modelo (igual que antes)\n",
        "    print(\"Configurando modelo OR-Tools...\");\n",
        "    try:\n",
        "        manager = pywrapcp.RoutingIndexManager(num_locations_total, num_vehicles, [source_node] * num_vehicles, [sink_node] * num_vehicles)\n",
        "        routing = pywrapcp.RoutingModel(manager); print(\"Manager y Modelo creados.\")\n",
        "    except Exception as e: print(f\"Error creando modelo OR-Tools: {e}\"); return\n",
        "\n",
        "    # 8. Callback de Tránsito (igual que antes)\n",
        "    def time_callback(from_index, to_index):\n",
        "        try:\n",
        "            from_node = manager.IndexToNode(from_index); to_node = manager.IndexToNode(to_index)\n",
        "            inter_travel_time = 0\n",
        "            if 0 <= from_node < num_jobs and 0 <= to_node < num_jobs: inter_travel_time = travel_times_min[from_node][to_node]\n",
        "            elif from_node == source_node and 0 <= to_node < num_jobs: inter_travel_time = 0\n",
        "            elif 0 <= from_node < num_jobs and to_node == sink_node: inter_travel_time = 0\n",
        "            elif from_node == source_node and to_node == sink_node: inter_travel_time = 0\n",
        "            else: return INF_TIME\n",
        "            origin_job_duration = 0\n",
        "            if 0 <= from_node < num_jobs: origin_job_duration = job_durations_min[from_node]\n",
        "            total_time = int(round(inter_travel_time + origin_job_duration))\n",
        "            return min(total_time, INF_TIME)\n",
        "        except IndexError: return INF_TIME\n",
        "        except Exception: return INF_TIME\n",
        "    transit_callback_index = routing.RegisterTransitCallback(time_callback)\n",
        "    routing.SetArcCostEvaluatorOfAllVehicles(transit_callback_index)\n",
        "    print(\"Callback de tiempo registrado y costo de arcos establecido.\")\n",
        "\n",
        "    # 9. Dimensión de Tiempo (igual que antes, con debug de SetRange)\n",
        "    print(\"Añadiendo dimensión de Tiempo...\"); time_dimension_name = \"Time\"\n",
        "    max_route_time_min = PARAM_MAX_HORAS_POR_MOVIL * 60\n",
        "    max_window_end = max(w[1] for w in pickup_windows_min) if pickup_windows_min else 0\n",
        "    horizon = max(max_window_end + max(job_durations_min) if job_durations_min else 0, max_route_time_min); horizon += max_route_time_min\n",
        "    print(f\"  Horizonte: {horizon} min, Capacidad Ruta: {max_route_time_min} min, Slack: {MAX_SLACK_MINUTES} min\")\n",
        "    routing.AddDimension(transit_callback_index, MAX_SLACK_MINUTES, max_route_time_min, False, time_dimension_name)\n",
        "    time_dimension = routing.GetDimensionOrDie(time_dimension_name); print(f\"Dimensión '{time_dimension_name}' añadida.\")\n",
        "    print(\"Aplicando ventanas de tiempo a los trabajos...\");\n",
        "    try:\n",
        "        for job_idx in range(num_jobs):\n",
        "            index = manager.NodeToIndex(job_idx); start_win, end_win = pickup_windows_min[job_idx]\n",
        "            job_id_display = tasks[job_idx].get(ID_COLUMN_NAME, job_idx)\n",
        "            # print(f\"DEBUG: SetRange Job {job_id_display} [{start_win}, {end_win}]\") # Descomentar para debug detallado\n",
        "            if start_win > end_win: raise ValueError(f\"Ventana inválida para Job {job_id_display}: [{start_win}, {end_win}]\")\n",
        "            time_dimension.CumulVar(index).SetRange(start_win, end_win)\n",
        "        source_index = manager.NodeToIndex(source_node)\n",
        "        # print(f\"DEBUG: SetRange Source [0, {horizon}]\") # Descomentar para debug detallado\n",
        "        time_dimension.CumulVar(source_index).SetRange(0, horizon)\n",
        "        print(\"Ventanas de tiempo aplicadas.\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\n!!! ERROR CRÍTICO al aplicar ventana de tiempo para Job {job_id_display} [{start_win}, {end_win}]: {e} !!!\"); return\n",
        "\n",
        "    # 10. Dimensión de Conteo de Trabajos (igual que antes)\n",
        "    print(f\"Añadiendo dimensión de Conteo de Trabajos (max: {PARAM_MAX_RESERVAS_POR_MOVIL})...\")\n",
        "    jobs_dimension_name = \"Jobs\";\n",
        "    try:\n",
        "        def demand_callback(from_index):\n",
        "            from_node = manager.IndexToNode(from_index); return 1 if 0 <= from_node < num_jobs else 0\n",
        "        demand_callback_index = routing.RegisterUnaryTransitCallback(demand_callback)\n",
        "        routing.AddDimensionWithVehicleCapacity(demand_callback_index, 0, [PARAM_MAX_RESERVAS_POR_MOVIL] * num_vehicles, True, jobs_dimension_name)\n",
        "        print(f\"Dimensión '{jobs_dimension_name}' añadida.\")\n",
        "    except Exception as e: print(f\"Error añadiendo dimensión '{jobs_dimension_name}': {e}\")\n",
        "\n",
        "    # 11. Configurar Búsqueda y Resolver (igual que antes)\n",
        "    print(\"Configurando parámetros de búsqueda y resolviendo...\")\n",
        "    search_parameters = pywrapcp.DefaultRoutingSearchParameters()\n",
        "    search_parameters.first_solution_strategy = routing_enums_pb2.FirstSolutionStrategy.AUTOMATIC\n",
        "    search_parameters.local_search_metaheuristic = routing_enums_pb2.LocalSearchMetaheuristic.GUIDED_LOCAL_SEARCH\n",
        "    search_parameters.time_limit.seconds = SOLVER_TIME_LIMIT_SECONDS\n",
        "    search_parameters.log_search = True\n",
        "    print(f\"Límite de tiempo del solver: {SOLVER_TIME_LIMIT_SECONDS} segundos.\")\n",
        "    solution = routing.SolveWithParameters(search_parameters)\n",
        "\n",
        "    # 12. Procesar Solución, Exportar y Mostrar Resumen\n",
        "    if solution:\n",
        "        print(\"\\n********************* Solución Encontrada! *********************\")\n",
        "        # --- Procesar la solución para obtener datos estructurados ---\n",
        "        solution_routes, assigned_job_node_indices, total_jobs_assigned = process_and_print_solution(\n",
        "            num_jobs, tasks, {\"num_vehicles\": num_vehicles, \"source_node\": source_node, \"sink_node\": sink_node},\n",
        "            manager, routing, solution\n",
        "        )\n",
        "\n",
        "        # --- Crear lista de trabajos asignados para df_rutas ---\n",
        "        rutas_asignadas_list = []\n",
        "        vehicle_map = {} # Mapea ID interno de OR-Tools a ID secuencial 1..N\n",
        "        next_movil_id = 1\n",
        "        for route in solution_routes:\n",
        "            or_tools_vehicle_id = route['or_tools_vehicle_id']\n",
        "            if or_tools_vehicle_id not in vehicle_map:\n",
        "                vehicle_map[or_tools_vehicle_id] = next_movil_id\n",
        "                current_movil_id = next_movil_id\n",
        "                next_movil_id += 1\n",
        "            else:\n",
        "                current_movil_id = vehicle_map[or_tools_vehicle_id]\n",
        "\n",
        "            # Añadir cada detalle de trabajo con el movil_id correcto\n",
        "            for job_detail in route['route_details']:\n",
        "                job_detail_export = job_detail.copy()\n",
        "                job_detail_export['movil_id'] = current_movil_id\n",
        "                # Eliminar claves internas si no se desean en el CSV\n",
        "                # del job_detail_export['or_tools_vehicle_id']\n",
        "                # del job_detail_export['node_index']\n",
        "                rutas_asignadas_list.append(job_detail_export)\n",
        "\n",
        "        df_rutas = pd.DataFrame(rutas_asignadas_list)\n",
        "        print(f\"\\nDataFrame 'df_rutas' creado con {len(df_rutas)} filas.\")\n",
        "\n",
        "        # --- Crear lista de trabajos NO asignados ---\n",
        "        reservas_no_asignadas_list = []\n",
        "        for job_idx in range(num_jobs):\n",
        "            if job_idx not in assigned_job_node_indices:\n",
        "                unassigned_task = tasks[job_idx].copy()\n",
        "                # Añadir motivo (simplificado para OR-Tools)\n",
        "                unassigned_task['motivo_no_asignado'] = \"No incluido en solución OR-Tools\"\n",
        "                reservas_no_asignadas_list.append(unassigned_task)\n",
        "\n",
        "        df_no_asignadas = pd.DataFrame(reservas_no_asignadas_list)\n",
        "        print(f\"DataFrame 'df_no_asignadas' creado con {len(df_no_asignadas)} filas.\")\n",
        "\n",
        "        # --- Exportar a CSV ---\n",
        "        rutas_csv_path = \"rutas_asignadas_ortools.csv\"\n",
        "        no_asignadas_csv_path = \"reservas_no_asignadas_ortools.csv\"\n",
        "        try:\n",
        "            df_rutas.to_csv(rutas_csv_path, index=False)\n",
        "            print(f\"Resultados de rutas asignadas exportados a: {rutas_csv_path}\")\n",
        "            df_no_asignadas.to_csv(no_asignadas_csv_path, index=False)\n",
        "            print(f\"Resultados de reservas no asignadas exportados a: {no_asignadas_csv_path}\")\n",
        "\n",
        "            # --- Descargar en Google Colab (si aplica) ---\n",
        "            if IN_COLAB:\n",
        "                print(\"Iniciando descarga de archivos en Colab...\")\n",
        "                files.download(rutas_csv_path)\n",
        "                files.download(no_asignadas_csv_path)\n",
        "            # --------------------------------------------\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\nError al exportar archivos CSV: {e}\")\n",
        "\n",
        "        # --- Imprimir Resumen Final ---\n",
        "        print(\"\\n--- Resumen Final ---\")\n",
        "        num_vehicles_used = len(solution_routes) # Número de vehículos con ruta asignada\n",
        "        total_payment_assigned = df_rutas['estimated_payment'].sum() if 'estimated_payment' in df_rutas.columns else 0\n",
        "\n",
        "        print(f\"✅ Móviles usados: {num_vehicles_used}\")\n",
        "        print(f\"✅ Trabajos asignados: {total_jobs_assigned}\")\n",
        "        print(f\"🚫 Trabajos NO asignados: {len(df_no_asignadas)}\")\n",
        "        # Formatear el pago total como moneda\n",
        "        try:\n",
        "             print(f\"💰 Ganancia total estimada (asignados): ${total_payment_assigned:,.0f}\")\n",
        "        except ValueError:\n",
        "             print(f\"💰 Ganancia total estimada (asignados): {total_payment_assigned}\") # Sin formato si falla\n",
        "\n",
        "        print(\"**********************************************************\\n\")\n",
        "\n",
        "    else:\n",
        "        # --- Si no se encontró solución ---\n",
        "        print(\"\\n******************** No se encontró solución ********************\")\n",
        "        print(\"  No se generaron archivos de resultados.\")\n",
        "        print(\"  Posibles causas: Restricciones muy estrictas, datos inconsistentes,\")\n",
        "        print(\"                   límite de tiempo insuficiente, no hay suficientes vehículos.\")\n",
        "        print(\"**********************************************************\\n\")\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Parte 5: Bloque de Ejecución Principal\n",
        "# ----------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "      # --- CONFIGURAR RUTAS A ARCHIVOS ---\n",
        "      hist_file = '/content/distancias H3 2.0 (Hist).csv'        # ¡¡¡ CAMBIA ESTO !!!\n",
        "      pred_file = '/content/distancias H3 2.0 (Pred) - 25-04 05-15.csv'    # ¡¡¡ CAMBIA ESTO !!!\n",
        "      # ------------------------------------\n",
        "\n",
        "      print(f\"Iniciando proceso de optimización de rutas...\")\n",
        "      print(f\"Archivo histórico: {hist_file}\")\n",
        "      print(f\"Archivo de predicciones: {pred_file}\")\n",
        "      print(f\"ID Column Name expected in predictions: '{ID_COLUMN_NAME}'\")\n",
        "\n",
        "      if not os.path.exists(hist_file):\n",
        "          print(f\"\\nERROR FATAL: El archivo histórico '{hist_file}' no existe.\")\n",
        "      elif not os.path.exists(pred_file):\n",
        "          print(f\"\\nERROR FATAL: El archivo de predicciones '{pred_file}' no existe.\")\n",
        "      else:\n",
        "          main_ortools(hist_file, pred_file)\n",
        "\n",
        "      print(\"Proceso finalizado.\")"
      ],
      "metadata": {
        "id": "IE73nbKM4Dkp",
        "outputId": "b267e45c-a8af-447c-bfff-7f5097b15b11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "IE73nbKM4Dkp",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando proceso de optimización de rutas...\n",
            "Archivo histórico: /content/distancias H3 2.0 (Hist).csv\n",
            "Archivo de predicciones: /content/distancias H3 2.0 (Pred) - 25-04 05-15.csv\n",
            "ID Column Name expected in predictions: 'job_id'\n",
            "Cargando archivos...\n",
            "Históricos cargados: 461962 filas\n",
            "Predicciones cargadas: 215 filas\n",
            "Validando y preparando datos de predicción...\n",
            "Horizonte de planificación inicia en: 2025-04-25 05:00:00\n",
            "Precalculando promedios históricos...\n",
            "Limpiando datos históricos...\n",
            "  85796 filas eliminadas por NaNs o tiempo inválido.\n",
            "Calculando H3 y distancias para datos históricos...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-384875a72c93>:82: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_hist['tiempoestimada'] = pd.to_numeric(df_hist['tiempoestimada'], errors='coerce')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  7 filas eliminadas por cálculo inválido de H3/distancia.\n",
            "Calculando tiempos promedio agrupados por H3...\n",
            "Se calcularon promedios históricos (mediana). 79205 pares H3 origen-destino encontrados.\n",
            "Calculando velocidad promedio global (fallback)...\n",
            "Velocidad promedio (mediana) calculada (fallback): 36.10 km/h\n",
            "Preparando lista de tareas (trabajos)...\n",
            "Número de trabajos a asignar: 215 (se saltaron 0)\n",
            "Número de vehículos a usar: 100\n",
            "Precalculando matriz de tiempos de viaje inter-trabajos...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando Matriz Tiempos: 100%|██████████| 215/215 [17:24<00:00,  4.86s/job]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriz de tiempos inter-trabajos calculada.\n",
            "Configurando modelo OR-Tools...\n",
            "Manager y Modelo creados.\n",
            "Callback de tiempo registrado y costo de arcos establecido.\n",
            "Añadiendo dimensión de Tiempo...\n",
            "  Horizonte: 1537 min, Capacidad Ruta: 600 min, Slack: 30 min\n",
            "Dimensión 'Time' añadida.\n",
            "Aplicando ventanas de tiempo a los trabajos...\n",
            "\n",
            "!!! ERROR CRÍTICO al aplicar ventana de tiempo para Job 23673492 [620, 680]: CP Solver fail !!!\n",
            "Proceso finalizado.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}