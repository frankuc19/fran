{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frankuc19/fran/blob/main/examples/notebook/constraint_solver/vrp_time_windows.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "google",
      "metadata": {
        "id": "google"
      },
      "source": [
        "##### Copyright 2025 Google LLC."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "apache",
      "metadata": {
        "id": "apache"
      },
      "source": [
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "basename",
      "metadata": {
        "id": "basename"
      },
      "source": [
        "# vrp_time_windows"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "link",
      "metadata": {
        "id": "link"
      },
      "source": [
        "<table align=\"left\">\n",
        "<td>\n",
        "<a href=\"https://colab.research.google.com/github/google/or-tools/blob/main/examples/notebook/constraint_solver/vrp_time_windows.ipynb\"><img src=\"https://raw.githubusercontent.com/google/or-tools/main/tools/colab_32px.png\"/>Run in Google Colab</a>\n",
        "</td>\n",
        "<td>\n",
        "<a href=\"https://github.com/google/or-tools/blob/main/ortools/constraint_solver/samples/vrp_time_windows.py\"><img src=\"https://raw.githubusercontent.com/google/or-tools/main/tools/github_32px.png\"/>View source on GitHub</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "doc",
      "metadata": {
        "id": "doc"
      },
      "source": [
        "First, you must install [ortools](https://pypi.org/project/ortools/) package in this colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "install",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "install",
        "outputId": "e525b69b-e951-42ae-d257-60532621143f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ortools\n",
            "  Downloading ortools-9.12.4544-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting absl-py>=2.0.0 (from ortools)\n",
            "  Downloading absl_py-2.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from ortools) (2.0.2)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ortools) (2.2.2)\n",
            "Requirement already satisfied: protobuf<5.30,>=5.29.3 in /usr/local/lib/python3.11/dist-packages (from ortools) (5.29.4)\n",
            "Requirement already satisfied: immutabledict>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from ortools) (4.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->ortools) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->ortools) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->ortools) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->ortools) (1.17.0)\n",
            "Downloading ortools-9.12.4544-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (24.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.9/24.9 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading absl_py-2.2.2-py3-none-any.whl (135 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.6/135.6 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: absl-py, ortools\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.4.0\n",
            "    Uninstalling absl-py-1.4.0:\n",
            "      Successfully uninstalled absl-py-1.4.0\n",
            "Successfully installed absl-py-2.2.2 ortools-9.12.4544\n",
            "Collecting h3\n",
            "  Downloading h3-4.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Downloading h3-4.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h3\n",
            "Successfully installed h3-4.2.2\n"
          ]
        }
      ],
      "source": [
        "%pip install ortools\n",
        "!pip install h3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "description",
      "metadata": {
        "id": "description"
      },
      "source": [
        "\n",
        "Vehicles Routing Problem (VRP) with Time Windows.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "code",
      "metadata": {
        "id": "code"
      },
      "outputs": [],
      "source": [
        "from ortools.constraint_solver import routing_enums_pb2\n",
        "from ortools.constraint_solver import pywrapcp\n",
        "\n",
        "\n",
        "\n",
        "def create_data_model():\n",
        "    \"\"\"Stores the data for the problem.\"\"\"\n",
        "    data = {}\n",
        "    data[\"time_matrix\"] = [\n",
        "        [0, 6, 9, 8, 7, 3, 6, 2, 3, 2, 6, 6, 4, 4, 5, 9, 7],\n",
        "        [6, 0, 8, 3, 2, 6, 8, 4, 8, 8, 13, 7, 5, 8, 12, 10, 14],\n",
        "        [9, 8, 0, 11, 10, 6, 3, 9, 5, 8, 4, 15, 14, 13, 9, 18, 9],\n",
        "        [8, 3, 11, 0, 1, 7, 10, 6, 10, 10, 14, 6, 7, 9, 14, 6, 16],\n",
        "        [7, 2, 10, 1, 0, 6, 9, 4, 8, 9, 13, 4, 6, 8, 12, 8, 14],\n",
        "        [3, 6, 6, 7, 6, 0, 2, 3, 2, 2, 7, 9, 7, 7, 6, 12, 8],\n",
        "        [6, 8, 3, 10, 9, 2, 0, 6, 2, 5, 4, 12, 10, 10, 6, 15, 5],\n",
        "        [2, 4, 9, 6, 4, 3, 6, 0, 4, 4, 8, 5, 4, 3, 7, 8, 10],\n",
        "        [3, 8, 5, 10, 8, 2, 2, 4, 0, 3, 4, 9, 8, 7, 3, 13, 6],\n",
        "        [2, 8, 8, 10, 9, 2, 5, 4, 3, 0, 4, 6, 5, 4, 3, 9, 5],\n",
        "        [6, 13, 4, 14, 13, 7, 4, 8, 4, 4, 0, 10, 9, 8, 4, 13, 4],\n",
        "        [6, 7, 15, 6, 4, 9, 12, 5, 9, 6, 10, 0, 1, 3, 7, 3, 10],\n",
        "        [4, 5, 14, 7, 6, 7, 10, 4, 8, 5, 9, 1, 0, 2, 6, 4, 8],\n",
        "        [4, 8, 13, 9, 8, 7, 10, 3, 7, 4, 8, 3, 2, 0, 4, 5, 6],\n",
        "        [5, 12, 9, 14, 12, 6, 6, 7, 3, 3, 4, 7, 6, 4, 0, 9, 2],\n",
        "        [9, 10, 18, 6, 8, 12, 15, 8, 13, 9, 13, 3, 4, 5, 9, 0, 9],\n",
        "        [7, 14, 9, 16, 14, 8, 5, 10, 6, 5, 4, 10, 8, 6, 2, 9, 0],\n",
        "    ]\n",
        "    data[\"time_windows\"] = [\n",
        "        (0, 5),  # depot\n",
        "        (7, 12),  # 1\n",
        "        (10, 15),  # 2\n",
        "        (16, 18),  # 3\n",
        "        (10, 13),  # 4\n",
        "        (0, 5),  # 5\n",
        "        (5, 10),  # 6\n",
        "        (0, 4),  # 7\n",
        "        (5, 10),  # 8\n",
        "        (0, 3),  # 9\n",
        "        (10, 16),  # 10\n",
        "        (10, 15),  # 11\n",
        "        (0, 5),  # 12\n",
        "        (5, 10),  # 13\n",
        "        (7, 8),  # 14\n",
        "        (10, 15),  # 15\n",
        "        (11, 15),  # 16\n",
        "    ]\n",
        "    data[\"num_vehicles\"] = 4\n",
        "    data[\"depot\"] = 0\n",
        "    return data\n",
        "\n",
        "\n",
        "def print_solution(data, manager, routing, solution):\n",
        "    \"\"\"Prints solution on console.\"\"\"\n",
        "    print(f\"Objective: {solution.ObjectiveValue()}\")\n",
        "    time_dimension = routing.GetDimensionOrDie(\"Time\")\n",
        "    total_time = 0\n",
        "    for vehicle_id in range(data[\"num_vehicles\"]):\n",
        "        if not routing.IsVehicleUsed(solution, vehicle_id):\n",
        "            continue\n",
        "        index = routing.Start(vehicle_id)\n",
        "        plan_output = f\"Route for vehicle {vehicle_id}:\\n\"\n",
        "        while not routing.IsEnd(index):\n",
        "            time_var = time_dimension.CumulVar(index)\n",
        "            plan_output += (\n",
        "                f\"{manager.IndexToNode(index)}\"\n",
        "                f\" Time({solution.Min(time_var)},{solution.Max(time_var)})\"\n",
        "                \" -> \"\n",
        "            )\n",
        "            index = solution.Value(routing.NextVar(index))\n",
        "        time_var = time_dimension.CumulVar(index)\n",
        "        plan_output += (\n",
        "            f\"{manager.IndexToNode(index)}\"\n",
        "            f\" Time({solution.Min(time_var)},{solution.Max(time_var)})\\n\"\n",
        "        )\n",
        "        plan_output += f\"Time of the route: {solution.Min(time_var)}min\\n\"\n",
        "        print(plan_output)\n",
        "        total_time += solution.Min(time_var)\n",
        "    print(f\"Total time of all routes: {total_time}min\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"Solve the VRP with time windows.\"\"\"\n",
        "    # Instantiate the data problem.\n",
        "    data = create_data_model()\n",
        "\n",
        "    # Create the routing index manager.\n",
        "    manager = pywrapcp.RoutingIndexManager(\n",
        "        len(data[\"time_matrix\"]), data[\"num_vehicles\"], data[\"depot\"]\n",
        "    )\n",
        "\n",
        "    # Create Routing Model.\n",
        "    routing = pywrapcp.RoutingModel(manager)\n",
        "\n",
        "    # Create and register a transit callback.\n",
        "    def time_callback(from_index, to_index):\n",
        "        \"\"\"Returns the travel time between the two nodes.\"\"\"\n",
        "        # Convert from routing variable Index to time matrix NodeIndex.\n",
        "        from_node = manager.IndexToNode(from_index)\n",
        "        to_node = manager.IndexToNode(to_index)\n",
        "        return data[\"time_matrix\"][from_node][to_node]\n",
        "\n",
        "    transit_callback_index = routing.RegisterTransitCallback(time_callback)\n",
        "\n",
        "    # Define cost of each arc.\n",
        "    routing.SetArcCostEvaluatorOfAllVehicles(transit_callback_index)\n",
        "\n",
        "    # Add Time Windows constraint.\n",
        "    time = \"Time\"\n",
        "    routing.AddDimension(\n",
        "        transit_callback_index,\n",
        "        30,  # allow waiting time\n",
        "        30,  # maximum time per vehicle\n",
        "        False,  # Don't force start cumul to zero.\n",
        "        time,\n",
        "    )\n",
        "    time_dimension = routing.GetDimensionOrDie(time)\n",
        "    # Add time window constraints for each location except depot.\n",
        "    for location_idx, time_window in enumerate(data[\"time_windows\"]):\n",
        "        if location_idx == data[\"depot\"]:\n",
        "            continue\n",
        "        index = manager.NodeToIndex(location_idx)\n",
        "        time_dimension.CumulVar(index).SetRange(time_window[0], time_window[1])\n",
        "    # Add time window constraints for each vehicle start node.\n",
        "    depot_idx = data[\"depot\"]\n",
        "    for vehicle_id in range(data[\"num_vehicles\"]):\n",
        "        index = routing.Start(vehicle_id)\n",
        "        time_dimension.CumulVar(index).SetRange(\n",
        "            data[\"time_windows\"][depot_idx][0], data[\"time_windows\"][depot_idx][1]\n",
        "        )\n",
        "\n",
        "    # Instantiate route start and end times to produce feasible times.\n",
        "    for i in range(data[\"num_vehicles\"]):\n",
        "        routing.AddVariableMinimizedByFinalizer(\n",
        "            time_dimension.CumulVar(routing.Start(i))\n",
        "        )\n",
        "        routing.AddVariableMinimizedByFinalizer(time_dimension.CumulVar(routing.End(i)))\n",
        "\n",
        "    # Setting first solution heuristic.\n",
        "    search_parameters = pywrapcp.DefaultRoutingSearchParameters()\n",
        "    search_parameters.first_solution_strategy = (\n",
        "        routing_enums_pb2.FirstSolutionStrategy.PATH_CHEAPEST_ARC\n",
        "    )\n",
        "\n",
        "    # Solve the problem.\n",
        "    solution = routing.SolveWithParameters(search_parameters)\n",
        "\n",
        "    # Print solution on console.\n",
        "    if solution:\n",
        "        print_solution(data, manager, routing, solution)\n",
        "\n",
        "\n",
        "main()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------------------------------------\n",
        "# Parte 1: Imports y Funciones del Script de Asignación\n",
        "# ----------------------------------------------------------\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import timedelta, datetime\n",
        "import math\n",
        "import h3 # Asegúrate de que h3 está instalado (!pip install h3) # H3 real no se usa, se simula\n",
        "from tqdm import tqdm # Para la barra de progreso\n",
        "import os # Para verificar existencia de archivos\n",
        "import time # Para medir tiempos (opcional)\n",
        "\n",
        "# --- Importar para descarga en Colab ---\n",
        "try:\n",
        "    from google.colab import files\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "# -------------------------------------\n",
        "\n",
        "import ortools # <--- AÑADE O ASEGÚRATE QUE ESTÉ ESTA LÍNEA\n",
        "# --- Imports de OR-Tools ---\n",
        "from ortools.constraint_solver import routing_enums_pb2\n",
        "from ortools.constraint_solver import pywrapcp\n",
        "# ---------------------------\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Parte 2: Constantes y Configuraciones Globales\n",
        "# ----------------------------------------------------------\n",
        "RADIO_TIERRA_KM = 6371\n",
        "PRECISION_H3_SIMULADA = 3 # Precisión para la simulación de H3\n",
        "DEFAULT_AVG_SPEED_KMH = 40\n",
        "\n",
        "# Parámetros del Modelo (¡Ajusta según sea necesario!)\n",
        "PARAM_MAX_MOVILES = 100\n",
        "PARAM_MAX_RESERVAS_POR_MOVIL = 5\n",
        "PARAM_MAX_HORAS_POR_MOVIL = 10\n",
        "ID_COLUMN_NAME = 'job_id' # <--- ¡¡¡ VERIFICA ESTE NOMBRE EN TU CSV DE PREDICCIONES !!!\n",
        "SOLVER_TIME_LIMIT_SECONDS = 60\n",
        "MAX_SLACK_MINUTES = 30\n",
        "PICKUP_WINDOW_DURATION_MINUTES = 60\n",
        "\n",
        "# Valor grande para representar infinito (en minutos)\n",
        "INF_TIME = 30 * 24 * 60 # 30 días en minutos\n",
        "\n",
        "# Variables globales para datos precalculados\n",
        "h3_time_lookup = {} # Diccionario para búsqueda rápida O(1)\n",
        "avg_speed_kmh = DEFAULT_AVG_SPEED_KMH\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Parte 3: Funciones de Cálculo (optimizadas donde es posible)\n",
        "# ----------------------------------------------------------\n",
        "\n",
        "def haversine(lat1, lon1, lat2, lon2):\n",
        "    \"\"\"Calcula la distancia Haversine entre dos puntos en KM.\"\"\"\n",
        "    # Manejo de NaNs al inicio\n",
        "    if pd.isna(lat1) or pd.isna(lon1) or pd.isna(lat2) or pd.isna(lon2):\n",
        "        return np.nan\n",
        "\n",
        "    # Convertir a radianes\n",
        "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
        "\n",
        "    # Fórmula Haversine\n",
        "    dlat = lat2 - lat1\n",
        "    dlon = lon2 - lon1\n",
        "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
        "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
        "    distance = RADIO_TIERRA_KM * c\n",
        "    return distance\n",
        "\n",
        "def simulate_h3_str(lat, lon, precision=PRECISION_H3_SIMULADA):\n",
        "     \"\"\"Genera un ID H3 string simulado basado en lat/lon redondeados.\"\"\"\n",
        "     if pd.isna(lat) or pd.isna(lon):\n",
        "         return None\n",
        "     # Usar f-string para eficiencia\n",
        "     return f\"{round(lat, precision)}_{round(lon, precision)}\"\n",
        "\n",
        "def precompute_historical_averages(df_hist):\n",
        "    \"\"\"\n",
        "    Calcula tiempos promedio desde datos históricos y velocidad fallback.\n",
        "    Almacena los promedios en un diccionario global para búsqueda rápida.\n",
        "    \"\"\"\n",
        "    global h3_time_lookup, avg_speed_kmh\n",
        "    required_hist_cols = {'latrecogida', 'lonrecogida', 'latdestino', 'londestino', 'tiempoestimada'}\n",
        "\n",
        "    print(\"Iniciando pre-cómputo de promedios históricos...\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    if not required_hist_cols.issubset(df_hist.columns):\n",
        "        missing = required_hist_cols - set(df_hist.columns)\n",
        "        raise ValueError(f\"El DataFrame histórico no tiene las columnas necesarias: {missing}\")\n",
        "\n",
        "    print(\"Limpiando datos históricos...\")\n",
        "    initial_rows = len(df_hist)\n",
        "    # Limpiar NaNs en columnas clave y convertir tiempo a numérico\n",
        "    df_hist = df_hist.dropna(subset=list(required_hist_cols))\n",
        "    df_hist['tiempoestimada'] = pd.to_numeric(df_hist['tiempoestimada'], errors='coerce')\n",
        "    df_hist = df_hist.dropna(subset=['tiempoestimada'])\n",
        "    df_hist = df_hist[df_hist['tiempoestimada'] > 0] # Asegurar tiempo positivo\n",
        "    cleaned_rows_1 = len(df_hist)\n",
        "    print(f\"  {initial_rows - cleaned_rows_1} filas eliminadas por NaNs o tiempo inválido.\")\n",
        "\n",
        "    if df_hist.empty:\n",
        "        print(\"Advertencia: No hay datos históricos válidos después de la limpieza inicial.\")\n",
        "        h3_time_lookup = {}\n",
        "        avg_speed_kmh = DEFAULT_AVG_SPEED_KMH\n",
        "        print(f\"Usando velocidad fallback por defecto: {avg_speed_kmh} km/h\")\n",
        "        return\n",
        "\n",
        "    print(\"Calculando H3 simulados y distancias para datos históricos...\")\n",
        "    # Usar .apply (más rápido que iterrows)\n",
        "    df_hist['h3_origin'] = df_hist.apply(\n",
        "        lambda row: simulate_h3_str(row['latrecogida'], row['lonrecogida']), axis=1\n",
        "    )\n",
        "    df_hist['h3_destino'] = df_hist.apply(\n",
        "        lambda row: simulate_h3_str(row['latdestino'], row['londestino']), axis=1\n",
        "    )\n",
        "    # Vectorizar cálculo de distancia si es posible (haversine no es trivial de vectorizar directamente en pandas apply)\n",
        "    # Mantenemos apply por simplicidad aquí, pero se podría optimizar más si fuera necesario\n",
        "    df_hist['distance_km'] = df_hist.apply(\n",
        "        lambda row: haversine(row['latrecogida'], row['lonrecogida'], row['latdestino'], row['londestino']), axis=1\n",
        "    )\n",
        "\n",
        "    # Filtrar filas donde H3 o distancia no se pudieron calcular o son inválidas\n",
        "    df_hist = df_hist.dropna(subset=['h3_origin', 'h3_destino', 'distance_km'])\n",
        "    df_hist = df_hist[df_hist['distance_km'] > 0.01] # Filtrar distancias muy pequeñas/inválidas\n",
        "    cleaned_rows_2 = len(df_hist)\n",
        "    print(f\"  {cleaned_rows_1 - cleaned_rows_2} filas eliminadas por cálculo inválido de H3/distancia.\")\n",
        "\n",
        "    if df_hist.empty:\n",
        "        print(\"Advertencia: No hay datos históricos válidos después de calcular H3/distancia.\")\n",
        "        h3_time_lookup = {}\n",
        "        avg_speed_kmh = DEFAULT_AVG_SPEED_KMH\n",
        "        print(f\"Usando velocidad fallback por defecto: {avg_speed_kmh} km/h\")\n",
        "        return\n",
        "\n",
        "    print(\"Calculando tiempos promedio (mediana) agrupados por H3...\")\n",
        "    # Calcular mediana de tiempos por par H3\n",
        "    avg_times_df = df_hist.groupby(['h3_origin', 'h3_destino'], as_index=False)['tiempoestimada'].median()\n",
        "    avg_times_df.rename(columns={'tiempoestimada': 'avg_travel_time_min'}, inplace=True)\n",
        "\n",
        "    # *** Optimización: Crear diccionario para búsqueda rápida ***\n",
        "    h3_time_lookup = {}\n",
        "    for _, row in avg_times_df.iterrows():\n",
        "        # Usar tupla como clave para el diccionario\n",
        "        h3_time_lookup[(row['h3_origin'], row['h3_destino'])] = int(round(row['avg_travel_time_min']))\n",
        "    print(f\"Diccionario de búsqueda rápida creado con {len(h3_time_lookup)} entradas H3 origen-destino.\")\n",
        "\n",
        "    print(\"Calculando velocidad promedio global (fallback)...\")\n",
        "    # Calcular velocidad solo para filas con distancia y tiempo válidos\n",
        "    df_hist['speed_kmh'] = (df_hist['distance_km'] / df_hist['tiempoestimada']) * 60\n",
        "    # Filtrar velocidades poco realistas antes de calcular la mediana\n",
        "    df_hist_valid_speed = df_hist[(df_hist['speed_kmh'] > 1) & (df_hist['speed_kmh'] < 120)]\n",
        "\n",
        "    if not df_hist_valid_speed.empty:\n",
        "        avg_speed_kmh = df_hist_valid_speed['speed_kmh'].median()\n",
        "        print(f\"Velocidad promedio (mediana) calculada (fallback): {avg_speed_kmh:.2f} km/h\")\n",
        "    else:\n",
        "        avg_speed_kmh = DEFAULT_AVG_SPEED_KMH\n",
        "        print(f\"No se pudieron calcular velocidades válidas. Usando fallback por defecto: {avg_speed_kmh} km/h\")\n",
        "\n",
        "    end_time = time.time()\n",
        "    print(f\"Pre-cómputo finalizado en {end_time - start_time:.2f} segundos.\")\n",
        "\n",
        "\n",
        "def get_travel_time_minutes(h3_origin, h3_dest, fallback_distance_km):\n",
        "    \"\"\"\n",
        "    Obtiene el tiempo de viaje en minutos entre H3 usando el diccionario precalculado.\n",
        "    Usa fallback basado en distancia y velocidad promedio si no se encuentra en el diccionario.\n",
        "    \"\"\"\n",
        "    global h3_time_lookup, avg_speed_kmh\n",
        "\n",
        "    # Intenta buscar en el diccionario (búsqueda rápida O(1) promedio)\n",
        "    travel_time = h3_time_lookup.get((h3_origin, h3_dest))\n",
        "\n",
        "    if travel_time is not None:\n",
        "        return travel_time # Devuelve el tiempo precalculado si existe\n",
        "\n",
        "    # Fallback: Calcular tiempo basado en distancia y velocidad promedio\n",
        "    if pd.notna(fallback_distance_km) and fallback_distance_km > 0 and avg_speed_kmh > 0:\n",
        "        calculated_time = (fallback_distance_km / avg_speed_kmh) * 60\n",
        "        # Asegurarse de devolver un entero y evitar tiempos cero si la distancia es muy pequeña\n",
        "        return max(1, int(round(calculated_time)))\n",
        "\n",
        "    # Si no hay datos suficientes para el fallback, devolver un tiempo por defecto (ej. 60 min)\n",
        "    # print(f\"WARN: Fallback para {h3_origin}-{h3_dest} sin distancia ({fallback_distance_km}) o velocidad ({avg_speed_kmh}). Usando 60min.\")\n",
        "    return 60\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Parte 4: Funciones de OR-Tools y Ejecución Principal (Optimizada)\n",
        "# ----------------------------------------------------------\n",
        "\n",
        "def process_and_print_solution(num_jobs, tasks, data, manager, routing, solution):\n",
        "    \"\"\"\n",
        "    Procesa la solución, la imprime de forma resumida y devuelve datos estructurados.\n",
        "    (Misma funcionalidad que antes, sólo se ajusta para la estructura de 'tasks')\n",
        "    \"\"\"\n",
        "    global ID_COLUMN_NAME\n",
        "\n",
        "    print(f\"\\nObjective (Total Time Minimizado): {solution.ObjectiveValue()} min\")\n",
        "    time_dimension = routing.GetDimensionOrDie(\"Time\")\n",
        "    jobs_dimension = routing.GetDimensionOrDie(\"Jobs\") # Puede ser None si falló la creación\n",
        "\n",
        "    solution_routes = [] # Lista para almacenar la información de cada ruta usada\n",
        "    assigned_job_node_indices = set() # Para rastrear qué trabajos se asignaron (índices 0 a num_jobs-1)\n",
        "    total_jobs_assigned_count = 0\n",
        "    total_route_time_sum = 0 # Suma del tiempo de las rutas usadas\n",
        "\n",
        "    print(\"\\n--- Rutas Asignadas ---\")\n",
        "    vehicles_used = 0\n",
        "    for vehicle_id in range(data[\"num_vehicles\"]):\n",
        "        if not routing.IsVehicleUsed(solution, vehicle_id):\n",
        "            continue\n",
        "\n",
        "        vehicles_used += 1\n",
        "        route_nodes_indices = [] # Indices de los trabajos en esta ruta\n",
        "        route_details_list = [] # Lista de diccionarios para los detalles de esta ruta\n",
        "        index = routing.Start(vehicle_id)\n",
        "        route_output = f\"Ruta Movil #{vehicles_used} (OR-Tools Veh {vehicle_id}): \"\n",
        "        current_job_count = 0\n",
        "        route_time = 0\n",
        "\n",
        "        while not routing.IsEnd(index):\n",
        "            node_index_internal = index\n",
        "            node_index_mapped = manager.IndexToNode(node_index_internal) # Mapea al índice 0..num_jobs-1 (+ source/sink)\n",
        "\n",
        "            # Solo procesar nodos de trabajo (ignorar source)\n",
        "            if 0 <= node_index_mapped < num_jobs:\n",
        "                job_idx = node_index_mapped # Índice del trabajo (0 a num_jobs-1)\n",
        "                task_info = tasks[job_idx] # Acceder a la tarea correcta por su índice\n",
        "                time_var = time_dimension.CumulVar(node_index_internal)\n",
        "                arrival_time_min = solution.Min(time_var)\n",
        "\n",
        "                job_id_display = task_info.get(ID_COLUMN_NAME, f\"JobIndex_{job_idx}\")\n",
        "                route_output += f\"{job_id_display} (Arr:{arrival_time_min}m) -> \"\n",
        "                current_job_count += 1\n",
        "\n",
        "                # Guardar detalles del trabajo asignado\n",
        "                job_detail = {\n",
        "                    \"movil_id_asignado\": vehicles_used, # ID Secuencial 1..N\n",
        "                    \"or_tools_vehicle_id\": vehicle_id, # ID interno de OR-Tools\n",
        "                    \"job_id_unique\": job_id_display, # El ID original del trabajo\n",
        "                    \"node_index\": job_idx, # Índice 0..num_jobs-1\n",
        "                    \"pickup_time_original\": task_info['pickup_time_str'],\n",
        "                    \"arrival_minutes_solution\": arrival_time_min,\n",
        "                    # Añadir otros datos relevantes de task_info\n",
        "                    \"estimated_payment\": task_info.get('estimated_payment', 0),\n",
        "                    \"pickup_lat\": task_info.get('pickup_lat'), \"pickup_lon\": task_info.get('pickup_lon'),\n",
        "                    \"dropoff_lat\": task_info.get('dropoff_lat'), \"dropoff_lon\": task_info.get('dropoff_lon'),\n",
        "                    \"job_duration_estimated_min\": task_info.get('job_duration_min')\n",
        "                }\n",
        "                route_details_list.append(job_detail)\n",
        "                route_nodes_indices.append(job_idx)\n",
        "                assigned_job_node_indices.add(job_idx) # Marcar como asignado (usa índice 0..N-1)\n",
        "\n",
        "            # Moverse al siguiente nodo en la ruta del vehículo\n",
        "            index = solution.Value(routing.NextVar(index))\n",
        "\n",
        "            # Si el siguiente es el final, obtener tiempo total de la ruta\n",
        "            if routing.IsEnd(index):\n",
        "                 time_var_end = time_dimension.CumulVar(index)\n",
        "                 route_time = solution.Min(time_var_end)\n",
        "                 total_route_time_sum += route_time # Acumular para el resumen\n",
        "\n",
        "        route_output += f\"End (Total: {route_time} min, Trabajos: {current_job_count})\"\n",
        "        print(route_output)\n",
        "\n",
        "        # Guardar información de la ruta completa\n",
        "        solution_routes.append({\n",
        "            \"movil_id_asignado\": vehicles_used,\n",
        "            \"or_tools_vehicle_id\": vehicle_id,\n",
        "            \"route_nodes_indices\": route_nodes_indices, # Lista de índices de trabajos\n",
        "            \"route_details\": route_details_list, # Lista de detalles por trabajo\n",
        "            \"total_route_time_min\": route_time,\n",
        "            \"total_jobs_in_route\": current_job_count\n",
        "        })\n",
        "        total_jobs_assigned_count += current_job_count # Contar trabajos\n",
        "\n",
        "    # Devolver los datos procesados\n",
        "    # total_jobs_assigned_count = len(assigned_job_node_indices) # Alternativa si solo contamos unicos\n",
        "    return solution_routes, assigned_job_node_indices, total_jobs_assigned_count, vehicles_used, total_route_time_sum\n",
        "\n",
        "\n",
        "def main_ortools(df_hist_path, df_pred_path):\n",
        "    \"\"\"\n",
        "    Función principal optimizada: carga datos, configura, resuelve y exporta.\n",
        "    \"\"\"\n",
        "    global ID_COLUMN_NAME, h3_time_lookup, avg_speed_kmh # Acceder a globales\n",
        "\n",
        "    main_start_time = time.time()\n",
        "\n",
        "    # 1. Cargar Datos\n",
        "    print(\"Cargando archivos CSV...\")\n",
        "    try:\n",
        "        df_hist = pd.read_csv(df_hist_path)\n",
        "        # Especificar dtypes puede acelerar la carga y evitar errores\n",
        "        dtypes_pred = {'latrecogida': float, 'lonrecogida': float,\n",
        "                       'latdestino': float, 'londestino': float,\n",
        "                       ID_COLUMN_NAME: str} # Asegurar que ID sea string si es necesario\n",
        "        df_pred = pd.read_csv(df_pred_path, dtype=dtypes_pred, low_memory=False)\n",
        "        print(f\"Históricos cargados: {len(df_hist)} filas\")\n",
        "        print(f\"Predicciones cargadas: {len(df_pred)} filas\")\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error CRÍTICO: No se encontró el archivo {e.filename}\")\n",
        "        return\n",
        "    except KeyError as e:\n",
        "        print(f\"Error CRÍTICO: Falta la columna '{e}' requerida en el dtype. Verifica el nombre '{ID_COLUMN_NAME}'.\")\n",
        "        return\n",
        "    except Exception as e:\n",
        "        print(f\"Error CRÍTICO cargando archivos CSV: {e}\")\n",
        "        return\n",
        "\n",
        "    # 2. Precomputar Promedios Históricos (Usa función optimizada)\n",
        "    try:\n",
        "        precompute_historical_averages(df_hist)\n",
        "    except ValueError as e:\n",
        "        print(f\"Error CRÍTICO en precomputo histórico: {e}\")\n",
        "        return\n",
        "    except Exception as e:\n",
        "        print(f\"Error CRÍTICO inesperado en precomputo histórico: {e}\")\n",
        "        return\n",
        "\n",
        "    # 3. Validar y Preparar Datos de Predicción (Optimizado)\n",
        "    print(\"Validando y preparando datos de predicción...\")\n",
        "    prep_start_time = time.time()\n",
        "    required_pred_cols = {'latrecogida', 'lonrecogida', 'latdestino', 'londestino', 'pickup_datetime', ID_COLUMN_NAME}\n",
        "    if not required_pred_cols.issubset(df_pred.columns):\n",
        "         missing_cols = required_pred_cols - set(df_pred.columns)\n",
        "         print(f\"Error CRÍTICO: Faltan columnas requeridas en predicciones: {missing_cols}\")\n",
        "         print(f\"Columnas encontradas: {list(df_pred.columns)}\")\n",
        "         return\n",
        "\n",
        "    # Asegurar columna de pago estimado\n",
        "    if 'estimated_payment' not in df_pred.columns:\n",
        "        print(\"Advertencia: Columna 'estimated_payment' no encontrada. Se usará 0.\")\n",
        "        df_pred['estimated_payment'] = 0\n",
        "    else:\n",
        "        df_pred['estimated_payment'] = pd.to_numeric(df_pred['estimated_payment'], errors='coerce').fillna(0)\n",
        "\n",
        "    # Convertir fecha/hora y manejar errores\n",
        "    try:\n",
        "        df_pred['HoraFecha'] = pd.to_datetime(df_pred['pickup_datetime'], errors='coerce')\n",
        "    except Exception as e:\n",
        "        print(f\"Error CRÍTICO convirtiendo 'pickup_datetime' a fecha: {e}\")\n",
        "        return\n",
        "\n",
        "    # Filtrar filas con datos inválidos esenciales *antes* de cálculos costosos\n",
        "    initial_pred_rows = len(df_pred)\n",
        "    cols_to_check_na = ['HoraFecha', 'latrecogida', 'lonrecogida', 'latdestino', 'londestino', ID_COLUMN_NAME]\n",
        "    df_pred_valid = df_pred.dropna(subset=cols_to_check_na).copy() # Usar .copy() para evitar SettingWithCopyWarning\n",
        "    if df_pred_valid.empty:\n",
        "        print(f\"Error CRÍTICO: No hay trabajos válidos después de eliminar NaNs en columnas clave. {initial_pred_rows} filas iniciales.\")\n",
        "        return\n",
        "    skipped_initial = initial_pred_rows - len(df_pred_valid)\n",
        "    print(f\"  {skipped_initial} trabajos iniciales descartados por NaNs en columnas clave.\")\n",
        "\n",
        "    # Calcular Horizonte de Tiempo\n",
        "    start_horizon_time = df_pred_valid['HoraFecha'].min()\n",
        "    print(f\"Horizonte de planificación inicia en: {start_horizon_time}\")\n",
        "\n",
        "    # Calcular columnas necesarias de forma más eficiente\n",
        "    print(\"Calculando H3, distancias, duraciones y ventanas de tiempo...\")\n",
        "    # Calcular H3 (usando apply)\n",
        "    df_pred_valid['H3_pickup'] = df_pred_valid.apply(lambda row: simulate_h3_str(row['latrecogida'], row['lonrecogida']), axis=1)\n",
        "    df_pred_valid['H3_dropoff'] = df_pred_valid.apply(lambda row: simulate_h3_str(row['latdestino'], row['londestino']), axis=1)\n",
        "\n",
        "    # Calcular distancia fallback (apply sigue siendo razonable aquí)\n",
        "    df_pred_valid['distance_job_km'] = df_pred_valid.apply(lambda row: haversine(row['latrecogida'], row['lonrecogida'], row['latdestino'], row['londestino']), axis=1)\n",
        "\n",
        "    # Calcular duración del trabajo (usa función get_travel_time optimizada)\n",
        "    df_pred_valid['job_duration_min'] = df_pred_valid.apply(\n",
        "        lambda row: get_travel_time_minutes(row['H3_pickup'], row['H3_dropoff'], row['distance_job_km']), axis=1\n",
        "    )\n",
        "\n",
        "    # Calcular ventanas de tiempo (vectorizado)\n",
        "    time_diff_seconds = (df_pred_valid['HoraFecha'] - start_horizon_time).dt.total_seconds()\n",
        "    df_pred_valid['pickup_start_min'] = (time_diff_seconds / 60).round().astype(int)\n",
        "    # Asegurar que no sea negativo si alguna fecha es anterior al mínimo (raro pero posible)\n",
        "    df_pred_valid['pickup_start_min'] = df_pred_valid['pickup_start_min'].clip(lower=0)\n",
        "    df_pred_valid['pickup_end_min'] = df_pred_valid['pickup_start_min'] + PICKUP_WINDOW_DURATION_MINUTES\n",
        "    df_pred_valid['pickup_time_str'] = df_pred_valid['HoraFecha'].dt.strftime('%Y-%m-%d %H:%M')\n",
        "\n",
        "    # Filtrar trabajos cuya duración calculada sea inválida (ej. si fallback falló)\n",
        "    final_valid_rows = len(df_pred_valid)\n",
        "    df_pred_valid = df_pred_valid.dropna(subset=['H3_pickup', 'H3_dropoff', 'distance_job_km', 'job_duration_min'])\n",
        "    df_pred_valid = df_pred_valid[df_pred_valid['job_duration_min'] < INF_TIME] # Filtrar duraciones infinitas\n",
        "    skipped_calculation = final_valid_rows - len(df_pred_valid)\n",
        "    if skipped_calculation > 0:\n",
        "        print(f\"  Advertencia: Se descartaron {skipped_calculation} trabajos adicionales debido a problemas en cálculo de H3/distancia/duración.\")\n",
        "\n",
        "    num_jobs = len(df_pred_valid)\n",
        "    if num_jobs == 0:\n",
        "        print(f\"Error CRÍTICO: No quedaron trabajos válidos después de todos los cálculos. Total inicial: {initial_pred_rows}, descartados: {skipped_initial + skipped_calculation}\")\n",
        "        return\n",
        "    print(f\"Número final de trabajos a asignar: {num_jobs}\")\n",
        "\n",
        "    # *** Optimización: Crear lista de tareas desde DataFrame ***\n",
        "    tasks = df_pred_valid.to_dict('records') # Mucho más rápido que iterrows\n",
        "\n",
        "    # Extraer datos necesarios para la matriz de tiempos en listas para acceso rápido\n",
        "    job_durations_min = df_pred_valid['job_duration_min'].tolist()\n",
        "    pickup_coords = list(zip(df_pred_valid['latrecogida'], df_pred_valid['lonrecogida']))\n",
        "    dropoff_coords = list(zip(df_pred_valid['latdestino'], df_pred_valid['londestino']))\n",
        "    h3_pickups = df_pred_valid['H3_pickup'].tolist()\n",
        "    h3_dropoffs = df_pred_valid['H3_dropoff'].tolist()\n",
        "    pickup_windows_min = list(zip(df_pred_valid['pickup_start_min'], df_pred_valid['pickup_end_min']))\n",
        "\n",
        "    prep_end_time = time.time()\n",
        "    print(f\"Preparación de datos finalizada en {prep_end_time - prep_start_time:.2f} segundos.\")\n",
        "\n",
        "\n",
        "    # 4. Configurar Nodos y Vehículos\n",
        "    num_vehicles = min(PARAM_MAX_MOVILES, num_jobs) # No usar más vehículos que trabajos\n",
        "    print(f\"Número de vehículos a usar: {num_vehicles}\")\n",
        "    num_locations_total = num_jobs + 2 # Trabajos + Source + Sink\n",
        "    source_node = num_jobs # Índice del nodo de origen\n",
        "    sink_node = num_jobs + 1 # Índice del nodo de destino (sumidero)\n",
        "\n",
        "    # 5. Precalcular Matriz de Tiempos (Optimizada internamente)\n",
        "    print(\"Precalculando matriz de tiempos de viaje inter-trabajos...\")\n",
        "    matrix_start_time = time.time()\n",
        "    # Inicializar con un valor grande (o 0 si se maneja en callback)\n",
        "    travel_times_min_matrix = [[0] * num_jobs for _ in range(num_jobs)]\n",
        "\n",
        "    # El bucle N^2 es necesario, pero el interior es más rápido ahora\n",
        "    for i in tqdm(range(num_jobs), desc=\"Calculando Matriz Tiempos\", unit=\"job\", ncols=100):\n",
        "        for j in range(num_jobs):\n",
        "            if i == j:\n",
        "                # No se puede viajar de un trabajo a sí mismo instantáneamente\n",
        "                travel_times_min_matrix[i][j] = INF_TIME\n",
        "                continue\n",
        "\n",
        "            # Obtener coordenadas y H3 precalculados de las listas\n",
        "            lat1, lon1 = dropoff_coords[i]\n",
        "            lat2, lon2 = pickup_coords[j]\n",
        "            h3_origin = h3_dropoffs[i] # El origen del viaje es el dropoff del trabajo anterior\n",
        "            h3_dest = h3_pickups[j]    # El destino del viaje es el pickup del siguiente\n",
        "\n",
        "            # Calcular distancia solo como fallback para get_travel_time_minutes\n",
        "            distance_km_fallback = haversine(lat1, lon1, lat2, lon2)\n",
        "\n",
        "            # Usar la función optimizada que busca en el diccionario primero\n",
        "            travel_times_min_matrix[i][j] = get_travel_time_minutes(h3_origin, h3_dest, distance_km_fallback)\n",
        "\n",
        "    matrix_end_time = time.time()\n",
        "    print(f\"Matriz de tiempos inter-trabajos calculada en {matrix_end_time - matrix_start_time:.2f} segundos.\")\n",
        "\n",
        "    # 6. Crear Manager y Modelo OR-Tools\n",
        "    print(\"Configurando modelo OR-Tools...\"); model_start_time = time.time()\n",
        "    try:\n",
        "        # Nodos de inicio (todos desde source) y fin (todos hacia sink)\n",
        "        start_nodes = [source_node] * num_vehicles\n",
        "        end_nodes = [sink_node] * num_vehicles\n",
        "        manager = pywrapcp.RoutingIndexManager(num_locations_total, num_vehicles, start_nodes, end_nodes)\n",
        "        routing = pywrapcp.RoutingModel(manager); print(\"Manager y Modelo creados.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error CRÍTICO creando modelo OR-Tools: {e}\"); return\n",
        "\n",
        "    # 7. Callback de Tránsito (Tiempo)\n",
        "    # Esta función ahora combina el tiempo de viaje inter-trabajo y la duración del trabajo origen\n",
        "    def time_callback(from_index, to_index):\n",
        "        \"\"\"Devuelve el tiempo total (viaje + servicio en origen) para ir de from_index a to_index.\"\"\"\n",
        "        try:\n",
        "            from_node = manager.IndexToNode(from_index)\n",
        "            to_node = manager.IndexToNode(to_index)\n",
        "\n",
        "            # Determinar tiempo de viaje entre nodos\n",
        "            travel_time = 0\n",
        "            if from_node == source_node and 0 <= to_node < num_jobs:\n",
        "                # Viaje desde el origen a la primera recogida: asumir tiempo 0 o un tiempo fijo si se conoce\n",
        "                # Podríamos calcular tiempo desde un depósito central a pickup_coords[to_node] si tuviéramos la ubicación del depósito\n",
        "                travel_time = 0 # Simplificación: tiempo de viaje desde source es 0\n",
        "            elif 0 <= from_node < num_jobs and 0 <= to_node < num_jobs:\n",
        "                # Viaje entre dos trabajos (usa la matriz precalculada)\n",
        "                travel_time = travel_times_min_matrix[from_node][to_node]\n",
        "            elif 0 <= from_node < num_jobs and to_node == sink_node:\n",
        "                # Viaje desde la última entrega al destino final (sink): asumir tiempo 0 o fijo\n",
        "                 travel_time = 0 # Simplificación: tiempo de viaje hacia sink es 0\n",
        "            elif from_node == source_node and to_node == sink_node:\n",
        "                 # Caso de vehículo no usado (source a sink directo)\n",
        "                 travel_time = 0\n",
        "            # else: # Otros casos (sink a source, sink a job, job a source) no deberían ocurrir en rutas válidas\n",
        "\n",
        "            # Obtener duración del servicio en el nodo de origen (si es un trabajo)\n",
        "            service_time = 0\n",
        "            if 0 <= from_node < num_jobs:\n",
        "                service_time = job_durations_min[from_node]\n",
        "\n",
        "            # Tiempo total = tiempo de viaje + tiempo de servicio en el nodo origen\n",
        "            total_time = travel_time + service_time\n",
        "\n",
        "            # Asegurarse de que no exceda INF_TIME y sea entero\n",
        "            return min(int(round(total_time)), INF_TIME)\n",
        "\n",
        "        except IndexError:\n",
        "             # print(f\"WARN: IndexError en time_callback({from_index}, {to_index}) -> Nodes ({from_node}, {to_node})\")\n",
        "             return INF_TIME # Penalización alta si algo falla\n",
        "        except Exception as e:\n",
        "             # print(f\"WARN: Exception en time_callback: {e}\")\n",
        "             return INF_TIME\n",
        "\n",
        "    transit_callback_index = routing.RegisterTransitCallback(time_callback)\n",
        "    # Establecer el costo de los arcos = tiempo (queremos minimizar tiempo total)\n",
        "    routing.SetArcCostEvaluatorOfAllVehicles(transit_callback_index)\n",
        "    print(\"Callback de tiempo registrado y costo de arcos establecido.\")\n",
        "\n",
        "    # 8. Dimensión de Tiempo (Restricciones de Ventana y Duración de Ruta) - CORREGIDO\n",
        "    print(\"Añadiendo dimensión de Tiempo...\"); time_dimension_name = \"Time\"\n",
        "\n",
        "    # Calcular el tiempo máximo de ruta permitido por vehículo\n",
        "    max_route_time_min = PARAM_MAX_HORAS_POR_MOVIL * 60\n",
        "\n",
        "    # Calcular un horizonte global suficientemente grande\n",
        "    # Debe ser al menos el fin de la ventana más tardía + duración + slack, o simplemente un valor grande seguro.\n",
        "    latest_window_end = max(w[1] for w in pickup_windows_min) if pickup_windows_min else 0\n",
        "    longest_job = max(job_durations_min) if job_durations_min else 0\n",
        "    # Un horizonte seguro sería el último momento posible para terminar un trabajo + un margen\n",
        "    horizon = latest_window_end + longest_job + MAX_SLACK_MINUTES\n",
        "    # O simplemente un valor muy grande si confiamos en max_route_time_min para limitar\n",
        "    # horizon = INF_TIME # Otra opción si las ventanas son razonables\n",
        "\n",
        "    print(f\"  Capacidad de Tiempo por Ruta (Vehículo): {max_route_time_min} min\")\n",
        "    print(f\"  Horizonte Global Máximo del Plan: {horizon} min\")\n",
        "    print(f\"  Slack máximo permitido por parada: {MAX_SLACK_MINUTES} min\")\n",
        "\n",
        "    # --- LLAMADA CORREGIDA A AddDimension ---\n",
        "    routing.AddDimension(\n",
        "        transit_callback_index,\n",
        "        MAX_SLACK_MINUTES,     # Slack máximo (tiempo de espera en cada nodo)\n",
        "        max_route_time_min,    # Capacidad: Tiempo MÁXIMO ACUMULADO por RUTA de vehículo\n",
        "        False,                 # NO empezar tiempo acumulado en cero para nodos de inicio\n",
        "        time_dimension_name\n",
        "    )\n",
        "    # -----------------------------------------\n",
        "    time_dimension = routing.GetDimensionOrDie(time_dimension_name); print(f\"Dimensión '{time_dimension_name}' añadida.\")\n",
        "\n",
        "    print(\"Aplicando ventanas de tiempo a los trabajos...\");\n",
        "    # Aplicar ventanas de recogida a cada nodo de trabajo\n",
        "    try:\n",
        "        for job_idx in range(num_jobs):\n",
        "            index = manager.NodeToIndex(job_idx)\n",
        "            start_win, end_win = pickup_windows_min[job_idx]\n",
        "\n",
        "            # Comprobación adicional (opcional pero útil para debug)\n",
        "            # if start_win > max_route_time_min:\n",
        "            #     print(f\"WARN: Job {job_idx} start window {start_win} potentially > max route time {max_route_time_min}\")\n",
        "            # if end_win > horizon:\n",
        "            #     print(f\"WARN: Job {job_idx} end window {end_win} > global horizon {horizon}\")\n",
        "\n",
        "            if start_win > end_win:\n",
        "                 job_id_display = tasks[job_idx].get(ID_COLUMN_NAME, job_idx)\n",
        "                 print(f\"Advertencia: Ventana inválida para Job {job_id_display}: [{start_win}, {end_win}]. Ajustando a [{start_win}, {start_win}].\")\n",
        "                 end_win = start_win\n",
        "\n",
        "            # Intentar aplicar la ventana de tiempo\n",
        "            # print(f\"DEBUG: Setting range for Job {job_idx} (Node {index}): [{start_win}, {end_win}]\") # Descomentar para debug\n",
        "            time_dimension.CumulVar(index).SetRange(start_win, end_win)\n",
        "\n",
        "        # Aplicar ventanas a los nodos de inicio/fin de los vehículos\n",
        "        # Permite que las rutas empiecen/terminen en cualquier momento dentro del horizonte global\n",
        "        for vehicle_id in range(num_vehicles):\n",
        "             start_index = routing.Start(vehicle_id)\n",
        "             end_index = routing.End(vehicle_id)\n",
        "             # print(f\"DEBUG: Setting range for Start Node Veh {vehicle_id}: [0, {horizon}]\") # Descomentar para debug\n",
        "             time_dimension.CumulVar(start_index).SetRange(0, horizon)\n",
        "             # print(f\"DEBUG: Setting range for End Node Veh {vehicle_id}: [0, {horizon}]\") # Descomentar para debug\n",
        "             time_dimension.CumulVar(end_index).SetRange(0, horizon) # El tiempo de finalización también debe estar dentro del horizonte\n",
        "\n",
        "        print(\"Ventanas de tiempo aplicadas.\")\n",
        "    except Exception as e:\n",
        "        # Captura más específica si el error persiste aquí\n",
        "        job_id_display = tasks[job_idx].get(ID_COLUMN_NAME, job_idx) # job_idx podría ser el último del bucle\n",
        "        print(f\"\\n!!! ERROR CRÍTICO al aplicar ventana de tiempo [{start_win}, {end_win}] para Job con índice {job_idx} ({job_id_display}): {e} !!!\")\n",
        "        print(f\"    Revisa si la ventana es compatible con max_route_time_min={max_route_time_min} y horizon={horizon}\")\n",
        "        return # Detener la ejecución si falla aquí\n",
        "\n",
        "    # 9. Dimensión de Conteo de Trabajos (Opcional, pero útil)\n",
        "    print(f\"Añadiendo dimensión de Conteo de Trabajos (max: {PARAM_MAX_RESERVAS_POR_MOVIL})...\")\n",
        "    jobs_dimension_name = \"Jobs\";\n",
        "    try:\n",
        "        # Callback: devuelve 1 para cada nodo de trabajo, 0 para source/sink\n",
        "        def demand_callback(from_index):\n",
        "            from_node = manager.IndexToNode(from_index)\n",
        "            return 1 if 0 <= from_node < num_jobs else 0\n",
        "\n",
        "        demand_callback_index = routing.RegisterUnaryTransitCallback(demand_callback)\n",
        "        # Capacidad de cada vehículo = máximo número de trabajos permitidos\n",
        "        vehicle_capacities = [PARAM_MAX_RESERVAS_POR_MOVIL] * num_vehicles\n",
        "        routing.AddDimensionWithVehicleCapacity(\n",
        "            demand_callback_index,\n",
        "            0,  # Slack (no aplica a conteo)\n",
        "            vehicle_capacities,\n",
        "            True,  # Empezar acumulado en cero\n",
        "            jobs_dimension_name\n",
        "        )\n",
        "        print(f\"Dimensión '{jobs_dimension_name}' añadida.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Advertencia: Error añadiendo dimensión '{jobs_dimension_name}': {e}. Continuará sin ella.\")\n",
        "\n",
        "\n",
        "    # 10. Configurar Búsqueda y Resolver\n",
        "    print(\"Configurando parámetros de búsqueda y resolviendo...\")\n",
        "    model_end_time = time.time()\n",
        "    print(f\"Configuración del modelo OR-Tools completada en {model_end_time - model_start_time:.2f} segundos.\")\n",
        "\n",
        "    search_parameters = pywrapcp.DefaultRoutingSearchParameters()\n",
        "    # Estrategia para encontrar la primera solución rápidamente\n",
        "    search_parameters.first_solution_strategy = (\n",
        "        routing_enums_pb2.FirstSolutionStrategy.AUTOMATIC # Buenas opciones: PATH_CHEAPEST_ARC, PARALLEL_CHEAPEST_INSERTION\n",
        "    )\n",
        "    # Metaheurística para mejorar la solución inicial\n",
        "    search_parameters.local_search_metaheuristic = (\n",
        "        routing_enums_pb2.LocalSearchMetaheuristic.GUIDED_LOCAL_SEARCH # Buenas opciones: GUIDED_LOCAL_SEARCH, TABU_SEARCH\n",
        "    )\n",
        "    # Límite de tiempo para la búsqueda\n",
        "    search_parameters.time_limit.seconds = SOLVER_TIME_LIMIT_SECONDS\n",
        "    # Loguear progreso de la búsqueda (útil para ver si se atasca)\n",
        "    search_parameters.log_search = True # Poner en False para menos output\n",
        "\n",
        "    print(f\"Límite de tiempo del solver: {SOLVER_TIME_LIMIT_SECONDS} segundos. Iniciando Solve()...\")\n",
        "    solve_start_time = time.time()\n",
        "    solution = routing.SolveWithParameters(search_parameters)\n",
        "    solve_end_time = time.time()\n",
        "    print(f\"Proceso de Solve() finalizado en {solve_end_time - solve_start_time:.2f} segundos.\")\n",
        "\n",
        "    # 11. Procesar Solución, Exportar y Mostrar Resumen\n",
        "    if solution:\n",
        "        print(\"\\n********************* Solución Encontrada! *********************\")\n",
        "        # --- Procesar la solución para obtener datos ---\n",
        "        solution_routes, assigned_job_node_indices, total_jobs_assigned, vehicles_used, total_route_time_sum = process_and_print_solution(\n",
        "            num_jobs, tasks, {\"num_vehicles\": num_vehicles, \"source_node\": source_node, \"sink_node\": sink_node},\n",
        "            manager, routing, solution\n",
        "        )\n",
        "\n",
        "        # --- Crear DataFrame de rutas asignadas ---\n",
        "        rutas_asignadas_list = []\n",
        "        for route in solution_routes:\n",
        "            # Añadir cada detalle de trabajo de la ruta a la lista general\n",
        "            rutas_asignadas_list.extend(route['route_details'])\n",
        "\n",
        "        df_rutas = pd.DataFrame(rutas_asignadas_list)\n",
        "        if not df_rutas.empty:\n",
        "             # Opcional: Ordenar por móvil y luego por hora de llegada\n",
        "             df_rutas.sort_values(by=['movil_id_asignado', 'arrival_minutes_solution'], inplace=True)\n",
        "        print(f\"\\nDataFrame 'df_rutas' creado con {len(df_rutas)} filas (trabajos asignados).\")\n",
        "\n",
        "        # --- Crear DataFrame de trabajos NO asignados ---\n",
        "        reservas_no_asignadas_list = []\n",
        "        all_original_indices = set(range(num_jobs)) # Indices 0 a num_jobs-1\n",
        "        unassigned_indices = all_original_indices - assigned_job_node_indices\n",
        "\n",
        "        for job_idx in unassigned_indices:\n",
        "            unassigned_task = tasks[job_idx].copy() # Obtener datos del trabajo original\n",
        "            # Añadir motivo (simplificado)\n",
        "            unassigned_task['motivo_no_asignado'] = \"No incluido en solución OR-Tools (restricciones/tiempo)\"\n",
        "            # Limpiar datos internos si no se quieren en el CSV\n",
        "            # keys_to_remove = ['pickup_start_min', 'pickup_end_min', ...]\n",
        "            reservas_no_asignadas_list.append(unassigned_task)\n",
        "\n",
        "        df_no_asignadas = pd.DataFrame(reservas_no_asignadas_list)\n",
        "        print(f\"DataFrame 'df_no_asignadas' creado con {len(df_no_asignadas)} filas (trabajos no asignados).\")\n",
        "\n",
        "        # --- Exportar a CSV ---\n",
        "        timestamp_str = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        rutas_csv_path = f\"rutas_asignadas_ortools_{timestamp_str}.csv\"\n",
        "        no_asignadas_csv_path = f\"reservas_no_asignadas_ortools_{timestamp_str}.csv\"\n",
        "        try:\n",
        "            if not df_rutas.empty:\n",
        "                 df_rutas.to_csv(rutas_csv_path, index=False, encoding='utf-8-sig') # utf-8-sig para mejor compatibilidad Excel\n",
        "                 print(f\"Resultados de rutas asignadas exportados a: {rutas_csv_path}\")\n",
        "            else:\n",
        "                 print(\"No se generó archivo de rutas asignadas (ningún trabajo asignado).\")\n",
        "\n",
        "            if not df_no_asignadas.empty:\n",
        "                 df_no_asignadas.to_csv(no_asignadas_csv_path, index=False, encoding='utf-8-sig')\n",
        "                 print(f\"Resultados de reservas no asignadas exportados a: {no_asignadas_csv_path}\")\n",
        "            else:\n",
        "                 print(\"No se generó archivo de reservas no asignadas (todos los trabajos asignados).\")\n",
        "\n",
        "\n",
        "            # --- Descargar en Google Colab (si aplica) ---\n",
        "            if IN_COLAB:\n",
        "                print(\"Iniciando descarga de archivos en Colab...\")\n",
        "                if not df_rutas.empty: files.download(rutas_csv_path)\n",
        "                if not df_no_asignadas.empty: files.download(no_asignadas_csv_path)\n",
        "                print(\"Descarga en Colab solicitada.\")\n",
        "            # --------------------------------------------\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\nError al exportar archivos CSV: {e}\")\n",
        "\n",
        "        # --- Imprimir Resumen Final ---\n",
        "        print(\"\\n--- Resumen Final de la Optimización ---\")\n",
        "        total_payment_assigned = df_rutas['estimated_payment'].sum() if not df_rutas.empty and 'estimated_payment' in df_rutas.columns else 0\n",
        "        avg_jobs_per_movil = total_jobs_assigned / vehicles_used if vehicles_used > 0 else 0\n",
        "        avg_time_per_movil = total_route_time_sum / vehicles_used if vehicles_used > 0 else 0\n",
        "\n",
        "        print(f\"Total Trabajos Input Válidos: {num_jobs}\")\n",
        "        print(f\"Móviles Utilizados:           {vehicles_used} / {num_vehicles}\")\n",
        "        print(f\"Trabajos Asignados:           {total_jobs_assigned}\")\n",
        "        print(f\"Trabajos NO Asignados:        {len(df_no_asignadas)}\")\n",
        "        print(f\"Objetivo OR-Tools (Tiempo):   {solution.ObjectiveValue()} min (Suma tiempos acumulados en nodos finales)\")\n",
        "        # print(f\"Suma Tiempos Rutas Usadas:    {total_route_time_sum} min\") # Puede diferir del objetivo dependiendo de la definición exacta\n",
        "        print(f\"Promedio Trabajos/Móvil:      {avg_jobs_per_movil:.2f}\")\n",
        "        print(f\"Promedio Tiempo/Móvil:        {avg_time_per_movil:.2f} min\")\n",
        "        # Formatear el pago total como moneda local (ejemplo CLP)\n",
        "        try:\n",
        "             print(f\"Ganancia Total Estimada:      ${total_payment_assigned:,.0f} CLP\")\n",
        "        except ValueError:\n",
        "             print(f\"Ganancia Total Estimada:      {total_payment_assigned}\") # Sin formato si falla\n",
        "\n",
        "    else:\n",
        "        # --- Si no se encontró solución ---\n",
        "        print(\"\\n******************** No se encontró solución ********************\")\n",
        "        print(\"El solver de OR-Tools no pudo encontrar una asignación factible dentro del tiempo límite y con las restricciones dadas.\")\n",
        "        print(\"Posibles causas:\")\n",
        "        print(\"  - Restricciones muy estrictas (ventanas de tiempo, capacidad móvil, tiempo máximo ruta).\")\n",
        "        print(\"  - Datos inconsistentes o geográficamente dispersos.\")\n",
        "        print(\"  - Límite de tiempo del solver (`SOLVER_TIME_LIMIT_SECONDS`) insuficiente.\")\n",
        "        print(\"  - Número insuficiente de vehículos (`PARAM_MAX_MOVILES`).\")\n",
        "        print(\"  - Errores en la definición del modelo o callbacks.\")\n",
        "        print(\"No se generaron archivos de resultados.\")\n",
        "\n",
        "    main_end_time = time.time()\n",
        "    print(f\"\\nProceso completo de optimización finalizado en {main_end_time - main_start_time:.2f} segundos.\")\n",
        "    print(\"**********************************************************\\n\")\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Parte 5: Bloque de Ejecución Principal\n",
        "# ----------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "      # --- ¡¡¡ CONFIGURA LAS RUTAS A TUS ARCHIVOS CSV !!! ---\n",
        "      hist_file = '/content/distancias H3 2.0 (Hist).csv'        # Ruta al archivo histórico\n",
        "      pred_file = '/content/distancias H3 2.0 (Pred) - 25-04 05-15.csv'    # Ruta al archivo de predicciones/trabajos\n",
        "      # ---------------------------------------------------------\n",
        "\n",
        "      print(f\"Iniciando proceso de optimización de rutas...\")\n",
        "      # --- LÍNEA CORREGIDA ---\n",
        "      try:\n",
        "            print(f\"Usando OR-Tools versión: {ortools.__version__}\")\n",
        "      except AttributeError:\n",
        "            print(\"No se pudo determinar la versión de OR-Tools automáticamente.\") # Fallback por si acaso\n",
        "      # -----------------------\n",
        "      print(f\"Archivo histórico:        {hist_file}\")\n",
        "      print(f\"Archivo de predicciones:  {pred_file}\")\n",
        "      print(f\"Columna ID de trabajo:    '{ID_COLUMN_NAME}'\")\n",
        "      print(\"-\" * 50)\n",
        "\n",
        "      # Verificar existencia de archivos antes de empezar\n",
        "      if not os.path.exists(hist_file):\n",
        "          print(f\"\\nERROR FATAL: El archivo histórico '{hist_file}' no existe.\")\n",
        "          print(\"Por favor, verifica la ruta y el nombre del archivo.\")\n",
        "      elif not os.path.exists(pred_file):\n",
        "          print(f\"\\nERROR FATAL: El archivo de predicciones '{pred_file}' no existe.\")\n",
        "          print(\"Por favor, verifica la ruta y el nombre del archivo.\")\n",
        "      else:\n",
        "          # Ejecutar la función principal\n",
        "          main_ortools(hist_file, pred_file)\n",
        "\n",
        "      print(\"Script finalizado.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IE73nbKM4Dkp",
        "outputId": "8966b4ac-7ef5-417b-ed86-52cd6f1f5a8c"
      },
      "id": "IE73nbKM4Dkp",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando proceso de optimización de rutas...\n",
            "Usando OR-Tools versión: 9.12.4544\n",
            "Archivo histórico:        /content/distancias H3 2.0 (Hist).csv\n",
            "Archivo de predicciones:  /content/distancias H3 2.0 (Pred) - 25-04 05-15.csv\n",
            "Columna ID de trabajo:    'job_id'\n",
            "--------------------------------------------------\n",
            "Cargando archivos CSV...\n",
            "Históricos cargados: 461962 filas\n",
            "Predicciones cargadas: 215 filas\n",
            "Iniciando pre-cómputo de promedios históricos...\n",
            "Limpiando datos históricos...\n",
            "  85796 filas eliminadas por NaNs o tiempo inválido.\n",
            "Calculando H3 simulados y distancias para datos históricos...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-a4c12e4e2a30>:98: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_hist['tiempoestimada'] = pd.to_numeric(df_hist['tiempoestimada'], errors='coerce')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  7 filas eliminadas por cálculo inválido de H3/distancia.\n",
            "Calculando tiempos promedio (mediana) agrupados por H3...\n",
            "Diccionario de búsqueda rápida creado con 79205 entradas H3 origen-destino.\n",
            "Calculando velocidad promedio global (fallback)...\n",
            "Velocidad promedio (mediana) calculada (fallback): 36.10 km/h\n",
            "Pre-cómputo finalizado en 23.30 segundos.\n",
            "Validando y preparando datos de predicción...\n",
            "  0 trabajos iniciales descartados por NaNs en columnas clave.\n",
            "Horizonte de planificación inicia en: 2025-04-25 05:00:00\n",
            "Calculando H3, distancias, duraciones y ventanas de tiempo...\n",
            "Número final de trabajos a asignar: 215\n",
            "Preparación de datos finalizada en 0.03 segundos.\n",
            "Número de vehículos a usar: 100\n",
            "Precalculando matriz de tiempos de viaje inter-trabajos...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando Matriz Tiempos: 100%|████████████████████████████████| 215/215 [00:00<00:00, 288.43job/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriz de tiempos inter-trabajos calculada en 0.75 segundos.\n",
            "Configurando modelo OR-Tools...\n",
            "Manager y Modelo creados.\n",
            "Callback de tiempo registrado y costo de arcos establecido.\n",
            "Añadiendo dimensión de Tiempo...\n",
            "  Capacidad de Tiempo por Ruta (Vehículo): 600 min\n",
            "  Horizonte Global Máximo del Plan: 967 min\n",
            "  Slack máximo permitido por parada: 30 min\n",
            "Dimensión 'Time' añadida.\n",
            "Aplicando ventanas de tiempo a los trabajos...\n",
            "\n",
            "!!! ERROR CRÍTICO al aplicar ventana de tiempo [620, 680] para Job con índice 208 (23673492): CP Solver fail !!!\n",
            "    Revisa si la ventana es compatible con max_route_time_min=600 y horizon=967\n",
            "Script finalizado.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}