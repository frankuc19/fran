{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frankuc19/fran/blob/main/examples/notebook/constraint_solver/vrp_time_windows.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "google",
      "metadata": {
        "id": "google"
      },
      "source": [
        "##### Copyright 2025 Google LLC."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "apache",
      "metadata": {
        "id": "apache"
      },
      "source": [
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "basename",
      "metadata": {
        "id": "basename"
      },
      "source": [
        "# vrp_time_windows"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "link",
      "metadata": {
        "id": "link"
      },
      "source": [
        "<table align=\"left\">\n",
        "<td>\n",
        "<a href=\"https://colab.research.google.com/github/google/or-tools/blob/main/examples/notebook/constraint_solver/vrp_time_windows.ipynb\"><img src=\"https://raw.githubusercontent.com/google/or-tools/main/tools/colab_32px.png\"/>Run in Google Colab</a>\n",
        "</td>\n",
        "<td>\n",
        "<a href=\"https://github.com/google/or-tools/blob/main/ortools/constraint_solver/samples/vrp_time_windows.py\"><img src=\"https://raw.githubusercontent.com/google/or-tools/main/tools/github_32px.png\"/>View source on GitHub</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "doc",
      "metadata": {
        "id": "doc"
      },
      "source": [
        "First, you must install [ortools](https://pypi.org/project/ortools/) package in this colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "install",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "install",
        "outputId": "e525b69b-e951-42ae-d257-60532621143f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ortools\n",
            "  Downloading ortools-9.12.4544-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting absl-py>=2.0.0 (from ortools)\n",
            "  Downloading absl_py-2.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from ortools) (2.0.2)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ortools) (2.2.2)\n",
            "Requirement already satisfied: protobuf<5.30,>=5.29.3 in /usr/local/lib/python3.11/dist-packages (from ortools) (5.29.4)\n",
            "Requirement already satisfied: immutabledict>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from ortools) (4.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->ortools) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->ortools) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->ortools) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->ortools) (1.17.0)\n",
            "Downloading ortools-9.12.4544-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (24.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.9/24.9 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading absl_py-2.2.2-py3-none-any.whl (135 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m135.6/135.6 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: absl-py, ortools\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.4.0\n",
            "    Uninstalling absl-py-1.4.0:\n",
            "      Successfully uninstalled absl-py-1.4.0\n",
            "Successfully installed absl-py-2.2.2 ortools-9.12.4544\n",
            "Collecting h3\n",
            "  Downloading h3-4.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Downloading h3-4.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h3\n",
            "Successfully installed h3-4.2.2\n"
          ]
        }
      ],
      "source": [
        "%pip install ortools\n",
        "!pip install h3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "description",
      "metadata": {
        "id": "description"
      },
      "source": [
        "\n",
        "Vehicles Routing Problem (VRP) with Time Windows.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "code",
      "metadata": {
        "id": "code"
      },
      "outputs": [],
      "source": [
        "from ortools.constraint_solver import routing_enums_pb2\n",
        "from ortools.constraint_solver import pywrapcp\n",
        "\n",
        "\n",
        "\n",
        "def create_data_model():\n",
        "    \"\"\"Stores the data for the problem.\"\"\"\n",
        "    data = {}\n",
        "    data[\"time_matrix\"] = [\n",
        "        [0, 6, 9, 8, 7, 3, 6, 2, 3, 2, 6, 6, 4, 4, 5, 9, 7],\n",
        "        [6, 0, 8, 3, 2, 6, 8, 4, 8, 8, 13, 7, 5, 8, 12, 10, 14],\n",
        "        [9, 8, 0, 11, 10, 6, 3, 9, 5, 8, 4, 15, 14, 13, 9, 18, 9],\n",
        "        [8, 3, 11, 0, 1, 7, 10, 6, 10, 10, 14, 6, 7, 9, 14, 6, 16],\n",
        "        [7, 2, 10, 1, 0, 6, 9, 4, 8, 9, 13, 4, 6, 8, 12, 8, 14],\n",
        "        [3, 6, 6, 7, 6, 0, 2, 3, 2, 2, 7, 9, 7, 7, 6, 12, 8],\n",
        "        [6, 8, 3, 10, 9, 2, 0, 6, 2, 5, 4, 12, 10, 10, 6, 15, 5],\n",
        "        [2, 4, 9, 6, 4, 3, 6, 0, 4, 4, 8, 5, 4, 3, 7, 8, 10],\n",
        "        [3, 8, 5, 10, 8, 2, 2, 4, 0, 3, 4, 9, 8, 7, 3, 13, 6],\n",
        "        [2, 8, 8, 10, 9, 2, 5, 4, 3, 0, 4, 6, 5, 4, 3, 9, 5],\n",
        "        [6, 13, 4, 14, 13, 7, 4, 8, 4, 4, 0, 10, 9, 8, 4, 13, 4],\n",
        "        [6, 7, 15, 6, 4, 9, 12, 5, 9, 6, 10, 0, 1, 3, 7, 3, 10],\n",
        "        [4, 5, 14, 7, 6, 7, 10, 4, 8, 5, 9, 1, 0, 2, 6, 4, 8],\n",
        "        [4, 8, 13, 9, 8, 7, 10, 3, 7, 4, 8, 3, 2, 0, 4, 5, 6],\n",
        "        [5, 12, 9, 14, 12, 6, 6, 7, 3, 3, 4, 7, 6, 4, 0, 9, 2],\n",
        "        [9, 10, 18, 6, 8, 12, 15, 8, 13, 9, 13, 3, 4, 5, 9, 0, 9],\n",
        "        [7, 14, 9, 16, 14, 8, 5, 10, 6, 5, 4, 10, 8, 6, 2, 9, 0],\n",
        "    ]\n",
        "    data[\"time_windows\"] = [\n",
        "        (0, 5),  # depot\n",
        "        (7, 12),  # 1\n",
        "        (10, 15),  # 2\n",
        "        (16, 18),  # 3\n",
        "        (10, 13),  # 4\n",
        "        (0, 5),  # 5\n",
        "        (5, 10),  # 6\n",
        "        (0, 4),  # 7\n",
        "        (5, 10),  # 8\n",
        "        (0, 3),  # 9\n",
        "        (10, 16),  # 10\n",
        "        (10, 15),  # 11\n",
        "        (0, 5),  # 12\n",
        "        (5, 10),  # 13\n",
        "        (7, 8),  # 14\n",
        "        (10, 15),  # 15\n",
        "        (11, 15),  # 16\n",
        "    ]\n",
        "    data[\"num_vehicles\"] = 4\n",
        "    data[\"depot\"] = 0\n",
        "    return data\n",
        "\n",
        "\n",
        "def print_solution(data, manager, routing, solution):\n",
        "    \"\"\"Prints solution on console.\"\"\"\n",
        "    print(f\"Objective: {solution.ObjectiveValue()}\")\n",
        "    time_dimension = routing.GetDimensionOrDie(\"Time\")\n",
        "    total_time = 0\n",
        "    for vehicle_id in range(data[\"num_vehicles\"]):\n",
        "        if not routing.IsVehicleUsed(solution, vehicle_id):\n",
        "            continue\n",
        "        index = routing.Start(vehicle_id)\n",
        "        plan_output = f\"Route for vehicle {vehicle_id}:\\n\"\n",
        "        while not routing.IsEnd(index):\n",
        "            time_var = time_dimension.CumulVar(index)\n",
        "            plan_output += (\n",
        "                f\"{manager.IndexToNode(index)}\"\n",
        "                f\" Time({solution.Min(time_var)},{solution.Max(time_var)})\"\n",
        "                \" -> \"\n",
        "            )\n",
        "            index = solution.Value(routing.NextVar(index))\n",
        "        time_var = time_dimension.CumulVar(index)\n",
        "        plan_output += (\n",
        "            f\"{manager.IndexToNode(index)}\"\n",
        "            f\" Time({solution.Min(time_var)},{solution.Max(time_var)})\\n\"\n",
        "        )\n",
        "        plan_output += f\"Time of the route: {solution.Min(time_var)}min\\n\"\n",
        "        print(plan_output)\n",
        "        total_time += solution.Min(time_var)\n",
        "    print(f\"Total time of all routes: {total_time}min\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"Solve the VRP with time windows.\"\"\"\n",
        "    # Instantiate the data problem.\n",
        "    data = create_data_model()\n",
        "\n",
        "    # Create the routing index manager.\n",
        "    manager = pywrapcp.RoutingIndexManager(\n",
        "        len(data[\"time_matrix\"]), data[\"num_vehicles\"], data[\"depot\"]\n",
        "    )\n",
        "\n",
        "    # Create Routing Model.\n",
        "    routing = pywrapcp.RoutingModel(manager)\n",
        "\n",
        "    # Create and register a transit callback.\n",
        "    def time_callback(from_index, to_index):\n",
        "        \"\"\"Returns the travel time between the two nodes.\"\"\"\n",
        "        # Convert from routing variable Index to time matrix NodeIndex.\n",
        "        from_node = manager.IndexToNode(from_index)\n",
        "        to_node = manager.IndexToNode(to_index)\n",
        "        return data[\"time_matrix\"][from_node][to_node]\n",
        "\n",
        "    transit_callback_index = routing.RegisterTransitCallback(time_callback)\n",
        "\n",
        "    # Define cost of each arc.\n",
        "    routing.SetArcCostEvaluatorOfAllVehicles(transit_callback_index)\n",
        "\n",
        "    # Add Time Windows constraint.\n",
        "    time = \"Time\"\n",
        "    routing.AddDimension(\n",
        "        transit_callback_index,\n",
        "        30,  # allow waiting time\n",
        "        30,  # maximum time per vehicle\n",
        "        False,  # Don't force start cumul to zero.\n",
        "        time,\n",
        "    )\n",
        "    time_dimension = routing.GetDimensionOrDie(time)\n",
        "    # Add time window constraints for each location except depot.\n",
        "    for location_idx, time_window in enumerate(data[\"time_windows\"]):\n",
        "        if location_idx == data[\"depot\"]:\n",
        "            continue\n",
        "        index = manager.NodeToIndex(location_idx)\n",
        "        time_dimension.CumulVar(index).SetRange(time_window[0], time_window[1])\n",
        "    # Add time window constraints for each vehicle start node.\n",
        "    depot_idx = data[\"depot\"]\n",
        "    for vehicle_id in range(data[\"num_vehicles\"]):\n",
        "        index = routing.Start(vehicle_id)\n",
        "        time_dimension.CumulVar(index).SetRange(\n",
        "            data[\"time_windows\"][depot_idx][0], data[\"time_windows\"][depot_idx][1]\n",
        "        )\n",
        "\n",
        "    # Instantiate route start and end times to produce feasible times.\n",
        "    for i in range(data[\"num_vehicles\"]):\n",
        "        routing.AddVariableMinimizedByFinalizer(\n",
        "            time_dimension.CumulVar(routing.Start(i))\n",
        "        )\n",
        "        routing.AddVariableMinimizedByFinalizer(time_dimension.CumulVar(routing.End(i)))\n",
        "\n",
        "    # Setting first solution heuristic.\n",
        "    search_parameters = pywrapcp.DefaultRoutingSearchParameters()\n",
        "    search_parameters.first_solution_strategy = (\n",
        "        routing_enums_pb2.FirstSolutionStrategy.PATH_CHEAPEST_ARC\n",
        "    )\n",
        "\n",
        "    # Solve the problem.\n",
        "    solution = routing.SolveWithParameters(search_parameters)\n",
        "\n",
        "    # Print solution on console.\n",
        "    if solution:\n",
        "        print_solution(data, manager, routing, solution)\n",
        "\n",
        "\n",
        "main()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------------------------------------\n",
        "# Parte 1: Imports y Funciones del Script de Asignaci√≥n\n",
        "# ----------------------------------------------------------\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import timedelta, datetime\n",
        "import math\n",
        "import h3 # Aseg√∫rate de que h3 est√° instalado (!pip install h3)\n",
        "from tqdm import tqdm # Para la barra de progreso\n",
        "import os # Para verificar existencia de archivos\n",
        "# --- Importar para descarga en Colab ---\n",
        "try:\n",
        "    from google.colab import files\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "# -------------------------------------\n",
        "\n",
        "# (El resto de imports de OR-Tools est√°n m√°s abajo)\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Parte 2: Constantes y Configuraciones Globales\n",
        "# ----------------------------------------------------------\n",
        "RADIO_TIERRA_KM = 6371\n",
        "PRECISION_H3 = 3\n",
        "DEFAULT_AVG_SPEED_KMH = 40\n",
        "\n",
        "# Par√°metros del Modelo (¬°Ajusta seg√∫n sea necesario!)\n",
        "PARAM_MAX_MOVILES = 100\n",
        "PARAM_MAX_RESERVAS_POR_MOVIL = 5\n",
        "PARAM_MAX_HORAS_POR_MOVIL = 10\n",
        "ID_COLUMN_NAME = 'job_id' # <--- ¬°¬°¬° VERIFICA ESTE NOMBRE !!!\n",
        "SOLVER_TIME_LIMIT_SECONDS = 60\n",
        "MAX_SLACK_MINUTES = 30\n",
        "PICKUP_WINDOW_DURATION_MINUTES = 60\n",
        "\n",
        "# Valor grande para representar infinito (en minutos)\n",
        "INF_TIME = 30 * 24 * 60\n",
        "\n",
        "# Variables globales para datos precalculados\n",
        "summary_df = pd.DataFrame()\n",
        "avg_speed_kmh = DEFAULT_AVG_SPEED_KMH\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Parte 3: Funciones de C√°lculo (haversine, simulate_h3_str, ...)\n",
        "# (Se mantienen igual que en la versi√≥n anterior - omitidas aqu√≠ por brevedad)\n",
        "# ... (incluye aqu√≠ las funciones haversine, simulate_h3_str,\n",
        "#      precompute_historical_averages, get_travel_time_minutes) ...\n",
        "# COPIAR FUNCIONES DE C√ÅLCULO DESDE LA RESPUESTA ANTERIOR AQU√ç\n",
        "def haversine(lat1, lon1, lat2, lon2):\n",
        "    \"\"\"Calcula la distancia Haversine entre dos puntos en KM.\"\"\"\n",
        "    coords = [lat1, lon1, lat2, lon2]\n",
        "    if any(map(lambda x: pd.isna(x) or x is None, coords)):\n",
        "        return np.nan\n",
        "    try:\n",
        "        lat1, lon1, lat2, lon2 = map(np.radians, coords)\n",
        "        dlat, dlon = lat2 - lat1, lon2 - lon1\n",
        "        a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
        "        c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
        "        distance = RADIO_TIERRA_KM * c\n",
        "        return distance\n",
        "    except ValueError as e:\n",
        "        # print(f\"Error calculando haversine para {coords}: {e}\") # Descomentar para debug\n",
        "        return np.nan\n",
        "\n",
        "def simulate_h3_str(lat, lon, precision=PRECISION_H3):\n",
        "     \"\"\"Genera un ID H3 string simulado basado en lat/lon redondeados.\"\"\"\n",
        "     if pd.isna(lat) or pd.isna(lon):\n",
        "         return None\n",
        "     return f\"{round(lat, precision)}_{round(lon, precision)}\"\n",
        "\n",
        "def precompute_historical_averages(df_hist):\n",
        "    \"\"\"Calcula tiempos promedio desde datos hist√≥ricos y velocidad fallback.\"\"\"\n",
        "    global summary_df, avg_speed_kmh\n",
        "    required_hist_cols = {'latrecogida', 'lonrecogida', 'latdestino', 'londestino', 'tiempoestimada'}\n",
        "    if not required_hist_cols.issubset(df_hist.columns):\n",
        "        missing = required_hist_cols - set(df_hist.columns)\n",
        "        raise ValueError(f\"El DataFrame hist√≥rico no tiene las columnas necesarias: {missing}\")\n",
        "    print(\"Limpiando datos hist√≥ricos...\")\n",
        "    initial_rows = len(df_hist)\n",
        "    df_hist = df_hist.dropna(subset=list(required_hist_cols))\n",
        "    df_hist['tiempoestimada'] = pd.to_numeric(df_hist['tiempoestimada'], errors='coerce')\n",
        "    df_hist = df_hist.dropna(subset=['tiempoestimada'])\n",
        "    df_hist = df_hist[df_hist['tiempoestimada'] > 0]\n",
        "    cleaned_rows_1 = len(df_hist)\n",
        "    print(f\"  {initial_rows - cleaned_rows_1} filas eliminadas por NaNs o tiempo inv√°lido.\")\n",
        "    if df_hist.empty:\n",
        "        # ... (manejo de error igual que antes) ...\n",
        "        print(\"Advertencia: No hay datos hist√≥ricos v√°lidos despu√©s de la limpieza inicial.\")\n",
        "        summary_df = pd.DataFrame(columns=['h3_origin', 'h3_destino', 'avg_travel_time_min'])\n",
        "        avg_speed_kmh = DEFAULT_AVG_SPEED_KMH\n",
        "        print(f\"Usando velocidad fallback por defecto: {avg_speed_kmh} km/h\")\n",
        "        return\n",
        "\n",
        "    print(\"Calculando H3 y distancias para datos hist√≥ricos...\")\n",
        "    df_hist['h3_origin'] = df_hist.apply(lambda row: simulate_h3_str(row['latrecogida'], row['lonrecogida']), axis=1)\n",
        "    df_hist['h3_destino'] = df_hist.apply(lambda row: simulate_h3_str(row['latdestino'], row['londestino']), axis=1)\n",
        "    df_hist['distance_km'] = df_hist.apply(lambda row: haversine(row['latrecogida'], row['lonrecogida'], row['latdestino'], row['londestino']), axis=1)\n",
        "    df_hist = df_hist.dropna(subset=['h3_origin', 'h3_destino', 'distance_km'])\n",
        "    df_hist = df_hist[df_hist['distance_km'] > 0.01]\n",
        "    cleaned_rows_2 = len(df_hist)\n",
        "    print(f\"  {cleaned_rows_1 - cleaned_rows_2} filas eliminadas por c√°lculo inv√°lido de H3/distancia.\")\n",
        "    if df_hist.empty:\n",
        "        # ... (manejo de error igual que antes) ...\n",
        "        print(\"Advertencia: No hay datos hist√≥ricos v√°lidos despu√©s de calcular H3/distancia.\")\n",
        "        summary_df = pd.DataFrame(columns=['h3_origin', 'h3_destino', 'avg_travel_time_min'])\n",
        "        avg_speed_kmh = DEFAULT_AVG_SPEED_KMH\n",
        "        print(f\"Usando velocidad fallback por defecto: {avg_speed_kmh} km/h\")\n",
        "        return\n",
        "\n",
        "    print(\"Calculando tiempos promedio agrupados por H3...\")\n",
        "    avg_times_df = df_hist.groupby(['h3_origin', 'h3_destino'], as_index=False)['tiempoestimada'].median()\n",
        "    avg_times_df.rename(columns={'tiempoestimada': 'avg_travel_time_min'}, inplace=True)\n",
        "    summary_df = avg_times_df\n",
        "    print(f\"Se calcularon promedios hist√≥ricos (mediana). {len(summary_df)} pares H3 origen-destino encontrados.\")\n",
        "\n",
        "    print(\"Calculando velocidad promedio global (fallback)...\")\n",
        "    df_hist['speed_kmh'] = (df_hist['distance_km'] / df_hist['tiempoestimada']) * 60\n",
        "    df_hist_valid_speed = df_hist[(df_hist['speed_kmh'] > 1) & (df_hist['speed_kmh'] < 120)]\n",
        "    if not df_hist_valid_speed.empty:\n",
        "        avg_speed_kmh = df_hist_valid_speed['speed_kmh'].median()\n",
        "        print(f\"Velocidad promedio (mediana) calculada (fallback): {avg_speed_kmh:.2f} km/h\")\n",
        "    else:\n",
        "        avg_speed_kmh = DEFAULT_AVG_SPEED_KMH\n",
        "        print(f\"No se pudieron calcular velocidades v√°lidas. Usando fallback por defecto: {avg_speed_kmh} km/h\")\n",
        "\n",
        "def get_travel_time_minutes(h3_origin, h3_dest, fallback_distance_km):\n",
        "    \"\"\"Obtiene el tiempo de viaje promedio en minutos entre H3. Usa fallback si no se encuentra.\"\"\"\n",
        "    if h3_origin is not None and h3_dest is not None and summary_df is not None and not summary_df.empty:\n",
        "        row = summary_df[(summary_df['h3_origin'] == h3_origin) & (summary_df['h3_destino'] == h3_dest)]\n",
        "        if not row.empty:\n",
        "            avg_time = row['avg_travel_time_min'].iloc[0]\n",
        "            if pd.notna(avg_time):\n",
        "                 return int(round(avg_time))\n",
        "    if pd.notna(fallback_distance_km) and avg_speed_kmh > 0:\n",
        "        calculated_time = (fallback_distance_km / avg_speed_kmh) * 60\n",
        "        return int(round(calculated_time))\n",
        "    return 60\n",
        "# ----------------------------------------------------------\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Parte 4: Funciones de OR-Tools y Ejecuci√≥n Principal\n",
        "# ----------------------------------------------------------\n",
        "from ortools.constraint_solver import routing_enums_pb2\n",
        "from ortools.constraint_solver import pywrapcp\n",
        "\n",
        "# --- MODIFICACI√ìN: print_solution ahora devuelve datos ---\n",
        "def process_and_print_solution(num_jobs, tasks, data, manager, routing, solution):\n",
        "    \"\"\"Procesa la soluci√≥n, la imprime y devuelve datos estructurados.\"\"\"\n",
        "    global ID_COLUMN_NAME\n",
        "\n",
        "    print(f\"\\nObjective (Total Time): {solution.ObjectiveValue()} min\")\n",
        "    time_dimension = routing.GetDimensionOrDie(\"Time\")\n",
        "    jobs_dimension = routing.GetDimensionOrDie(\"Jobs\") # Puede ser None\n",
        "\n",
        "    solution_routes = [] # Lista para almacenar la informaci√≥n de cada ruta usada\n",
        "    assigned_job_node_indices = set() # Para rastrear qu√© trabajos se asignaron\n",
        "\n",
        "    print(\"\\n--- Routes ---\")\n",
        "    for vehicle_id in range(data[\"num_vehicles\"]):\n",
        "        if not routing.IsVehicleUsed(solution, vehicle_id):\n",
        "            continue\n",
        "\n",
        "        route_nodes_indices = []\n",
        "        route_details_list = [] # Lista de diccionarios para los detalles de esta ruta\n",
        "        index = routing.Start(vehicle_id)\n",
        "        plan_output = f\"Route for vehicle {vehicle_id}:\\n\"\n",
        "        plan_output += \"  Start (Source) -> \"\n",
        "        route_time = 0\n",
        "\n",
        "        while True:\n",
        "            node_index_internal = index\n",
        "            node_index_mapped = manager.IndexToNode(node_index_internal)\n",
        "\n",
        "            if 0 <= node_index_mapped < num_jobs: # Es un nodo de trabajo\n",
        "                job_idx = node_index_mapped\n",
        "                task_info = tasks[job_idx]\n",
        "                time_var = time_dimension.CumulVar(node_index_internal)\n",
        "                arrival_time_min = solution.Min(time_var)\n",
        "                arrival_time_max = solution.Max(time_var)\n",
        "                job_count_at_node = \"N/A\"\n",
        "                if jobs_dimension:\n",
        "                    try:\n",
        "                        jobs_var = jobs_dimension.CumulVar(node_index_internal)\n",
        "                        job_count_at_node = solution.Value(jobs_var)\n",
        "                    except Exception: pass\n",
        "\n",
        "                plan_output += (\n",
        "                    f\"Job_{task_info.get(ID_COLUMN_NAME, job_idx)}\"\n",
        "                    f\" [P:{task_info['pickup_time_str']}]\"\n",
        "                    f\" (Arr: {arrival_time_min}-{arrival_time_max} min)\"\n",
        "                    f\" (Jobs: {job_count_at_node})\"\n",
        "                    \" -> \"\n",
        "                )\n",
        "                # Guardar detalles del trabajo asignado\n",
        "                job_detail = {\n",
        "                    \"or_tools_vehicle_id\": vehicle_id, # ID interno de OR-Tools\n",
        "                    \"job_id_unique\": task_info.get(ID_COLUMN_NAME, job_idx), # El ID del trabajo\n",
        "                    \"node_index\": job_idx, # √çndice 0..num_jobs-1\n",
        "                    \"pickup_time_original\": task_info['pickup_time_str'],\n",
        "                    \"arrival_minutes_min\": arrival_time_min,\n",
        "                    \"arrival_minutes_max\": arrival_time_max,\n",
        "                    \"job_count_at_node\": job_count_at_node,\n",
        "                    # A√±adir otros datos relevantes de task_info si es necesario\n",
        "                    \"estimated_payment\": task_info.get('estimated_payment', 0), # Incluir pago\n",
        "                    \"pickup_lat\": task_info.get('pickup_lat'),\n",
        "                    \"pickup_lon\": task_info.get('pickup_lon'),\n",
        "                    \"dropoff_lat\": task_info.get('dropoff_lat'),\n",
        "                    \"dropoff_lon\": task_info.get('dropoff_lon'),\n",
        "                }\n",
        "                route_details_list.append(job_detail)\n",
        "                route_nodes_indices.append(job_idx)\n",
        "                assigned_job_node_indices.add(job_idx) # Marcar como asignado\n",
        "\n",
        "            if routing.IsEnd(index):\n",
        "                if node_index_mapped == data[\"sink_node\"]:\n",
        "                    time_var_end = time_dimension.CumulVar(node_index_internal)\n",
        "                    route_time = solution.Min(time_var_end)\n",
        "                    plan_output += f\"End (Sink) [Total Time: {route_time} min]\"\n",
        "                else:\n",
        "                    plan_output += f\"End (Node {node_index_mapped}?) [Incomplete Route Trace]\"\n",
        "                    route_time = solution.ObjectiveValue()\n",
        "                break\n",
        "            index = solution.Value(routing.NextVar(index))\n",
        "\n",
        "        print(plan_output)\n",
        "        print(f\"  Jobs in route: {len(route_nodes_indices)}\")\n",
        "\n",
        "        # Guardar informaci√≥n de la ruta completa\n",
        "        solution_routes.append({\n",
        "            \"or_tools_vehicle_id\": vehicle_id,\n",
        "            \"route_nodes\": route_nodes_indices, # Lista de √≠ndices de trabajos\n",
        "            \"route_details\": route_details_list, # Lista de detalles por trabajo\n",
        "            \"total_route_time_min\": route_time,\n",
        "            \"total_jobs_in_route\": len(route_nodes_indices)\n",
        "        })\n",
        "\n",
        "    total_jobs_assigned = len(assigned_job_node_indices)\n",
        "    print(f\"\\n--- Summary ---\")\n",
        "    print(f\"Total time of all routes: {solution.ObjectiveValue()} min\") # Usar valor objetivo para tiempo total\n",
        "    print(f\"Total jobs assigned: {total_jobs_assigned} / {num_jobs}\")\n",
        "\n",
        "    # Devolver los datos procesados\n",
        "    return solution_routes, assigned_job_node_indices, total_jobs_assigned\n",
        "# --- Fin de la funci√≥n modificada ---\n",
        "\n",
        "\n",
        "def main_ortools(df_hist_path, df_pred_path):\n",
        "    \"\"\"Funci√≥n principal que carga datos, configura, resuelve y exporta.\"\"\"\n",
        "    global ID_COLUMN_NAME\n",
        "\n",
        "    # 1. Cargar Datos y 2. Validar Predicciones (igual que antes)\n",
        "    print(\"Cargando archivos...\")\n",
        "    try:\n",
        "        df_hist = pd.read_csv(df_hist_path)\n",
        "        dtypes_pred = {'latrecogida': float, 'lonrecogida': float, 'latdestino': float, 'londestino': float}\n",
        "        df_pred = pd.read_csv(df_pred_path, dtype=dtypes_pred, low_memory=False)\n",
        "        print(f\"Hist√≥ricos cargados: {len(df_hist)} filas\")\n",
        "        print(f\"Predicciones cargadas: {len(df_pred)} filas\")\n",
        "    except FileNotFoundError as e: print(f\"Error: No se encontr√≥ el archivo {e.filename}\"); return\n",
        "    except Exception as e: print(f\"Error cargando archivos CSV: {e}\"); return\n",
        "\n",
        "    print(\"Validando y preparando datos de predicci√≥n...\")\n",
        "    required_pred_cols = {'latrecogida', 'lonrecogida', 'latdestino', 'londestino', 'pickup_datetime', ID_COLUMN_NAME}\n",
        "    if not required_pred_cols.issubset(df_pred.columns):\n",
        "         missing_cols = required_pred_cols - set(df_pred.columns)\n",
        "         print(f\"Error: Faltan columnas requeridas en predicciones: {missing_cols}\")\n",
        "         print(f\"Columnas encontradas: {list(df_pred.columns)}\"); return\n",
        "    if 'estimated_payment' not in df_pred.columns:\n",
        "        print(\"Advertencia: Columna 'estimated_payment' no encontrada. Se usar√° 0.\")\n",
        "        df_pred['estimated_payment'] = 0\n",
        "    else:\n",
        "         # Asegurarse que sea num√©rico\n",
        "         df_pred['estimated_payment'] = pd.to_numeric(df_pred['estimated_payment'], errors='coerce').fillna(0)\n",
        "\n",
        "\n",
        "    try:\n",
        "        df_pred['HoraFecha'] = pd.to_datetime(df_pred['pickup_datetime'], errors='coerce')\n",
        "    except Exception as e: print(f\"Error convirtiendo 'pickup_datetime' a fecha: {e}\"); return\n",
        "    df_pred = df_pred.dropna(subset=['HoraFecha'])\n",
        "    if df_pred.empty: print(\"Error: No hay fechas v√°lidas ('pickup_datetime').\"); return\n",
        "    start_horizon_time = df_pred['HoraFecha'].min()\n",
        "    print(f\"Horizonte de planificaci√≥n inicia en: {start_horizon_time}\")\n",
        "\n",
        "    # 3. Precomputar Promedios (igual que antes)\n",
        "    print(\"Precalculando promedios hist√≥ricos...\")\n",
        "    try: precompute_historical_averages(df_hist)\n",
        "    except ValueError as e: print(f\"Error en precomputo hist√≥rico: {e}\"); return\n",
        "    except Exception as e: print(f\"Error inesperado en precomputo hist√≥rico: {e}\"); return\n",
        "\n",
        "    # 4. Preparar Lista de Tareas (igual que antes, asegurando 'estimated_payment')\n",
        "    print(\"Preparando lista de tareas (trabajos)...\")\n",
        "    tasks = []\n",
        "    job_durations_min = []\n",
        "    pickup_coords = []\n",
        "    dropoff_coords = []\n",
        "    pickup_windows_min = []\n",
        "    skipped_jobs = 0\n",
        "    for idx, row in df_pred.iterrows():\n",
        "        required_row_data = ['latrecogida', 'lonrecogida', 'latdestino', 'londestino', 'HoraFecha']\n",
        "        if any(pd.isna(row[col]) for col in required_row_data):\n",
        "             job_id_display = row.get(ID_COLUMN_NAME, f\"index_{idx}\")\n",
        "             print(f\"Advertencia: Saltando trabajo '{job_id_display}' por datos faltantes.\")\n",
        "             skipped_jobs += 1; continue\n",
        "        h3_pickup = simulate_h3_str(row['latrecogida'], row['lonrecogida'])\n",
        "        h3_dropoff = simulate_h3_str(row['latdestino'], row['londestino'])\n",
        "        distance_job_km = haversine(row['latrecogida'], row['lonrecogida'], row['latdestino'], row['londestino'])\n",
        "        job_duration = get_travel_time_minutes(h3_pickup, h3_dropoff, distance_job_km)\n",
        "        job_durations_min.append(job_duration)\n",
        "        earliest_pickup_time = row['HoraFecha']\n",
        "        pickup_start_min = int(round((earliest_pickup_time - start_horizon_time).total_seconds() / 60))\n",
        "        pickup_end_min = pickup_start_min + PICKUP_WINDOW_DURATION_MINUTES\n",
        "        pickup_windows_min.append((max(0, pickup_start_min), pickup_end_min))\n",
        "        task_data = {\n",
        "            \"original_index\": idx,\n",
        "            ID_COLUMN_NAME : row.get(ID_COLUMN_NAME),\n",
        "            \"pickup_lat\": row['latrecogida'],\"pickup_lon\": row['lonrecogida'],\n",
        "            \"dropoff_lat\": row['latdestino'],\"dropoff_lon\": row['londestino'],\n",
        "            \"h3_pickup\": h3_pickup,\"h3_dropoff\": h3_dropoff,\n",
        "            \"pickup_time\": earliest_pickup_time,\"pickup_time_str\": earliest_pickup_time.strftime('%Y-%m-%d %H:%M'),\n",
        "            # Incluir estimated_payment en los datos de la tarea\n",
        "            \"estimated_payment\": row.get('estimated_payment', 0)\n",
        "        }\n",
        "        tasks.append(task_data)\n",
        "        pickup_coords.append((row['latrecogida'], row['lonrecogida']))\n",
        "        dropoff_coords.append((row['latdestino'], row['londestino']))\n",
        "    num_jobs = len(tasks)\n",
        "    if num_jobs == 0: print(f\"Error: No hay trabajos v√°lidos (se saltaron {skipped_jobs}).\"); return\n",
        "    print(f\"N√∫mero de trabajos a asignar: {num_jobs} (se saltaron {skipped_jobs})\")\n",
        "\n",
        "    # 5. Configurar Nodos y Veh√≠culos (igual que antes)\n",
        "    num_vehicles = min(PARAM_MAX_MOVILES, num_jobs)\n",
        "    print(f\"N√∫mero de veh√≠culos a usar: {num_vehicles}\")\n",
        "    num_locations_total = num_jobs + 2\n",
        "    source_node = num_jobs\n",
        "    sink_node = num_jobs + 1\n",
        "\n",
        "    # 6. Precalcular Matriz de Tiempos (igual que antes, con tqdm)\n",
        "    print(\"Precalculando matriz de tiempos de viaje inter-trabajos...\")\n",
        "    travel_times_min = [[0] * num_jobs for _ in range(num_jobs)]\n",
        "    for i in tqdm(range(num_jobs), desc=\"Calculando Matriz Tiempos\", unit=\"job\"):\n",
        "        for j in range(num_jobs):\n",
        "            if i == j: travel_times_min[i][j] = INF_TIME; continue\n",
        "            lat1, lon1 = dropoff_coords[i]; lat2, lon2 = pickup_coords[j]\n",
        "            h3_origin = tasks[i][\"h3_dropoff\"]; h3_dest = tasks[j][\"h3_pickup\"]\n",
        "            distance_km_fallback = haversine(lat1, lon1, lat2, lon2)\n",
        "            travel_times_min[i][j] = get_travel_time_minutes(h3_origin, h3_dest, distance_km_fallback)\n",
        "    print(\"Matriz de tiempos inter-trabajos calculada.\")\n",
        "\n",
        "    # 7. Crear Manager y Modelo (igual que antes)\n",
        "    print(\"Configurando modelo OR-Tools...\");\n",
        "    try:\n",
        "        manager = pywrapcp.RoutingIndexManager(num_locations_total, num_vehicles, [source_node] * num_vehicles, [sink_node] * num_vehicles)\n",
        "        routing = pywrapcp.RoutingModel(manager); print(\"Manager y Modelo creados.\")\n",
        "    except Exception as e: print(f\"Error creando modelo OR-Tools: {e}\"); return\n",
        "\n",
        "    # 8. Callback de Tr√°nsito (igual que antes)\n",
        "    def time_callback(from_index, to_index):\n",
        "        try:\n",
        "            from_node = manager.IndexToNode(from_index); to_node = manager.IndexToNode(to_index)\n",
        "            inter_travel_time = 0\n",
        "            if 0 <= from_node < num_jobs and 0 <= to_node < num_jobs: inter_travel_time = travel_times_min[from_node][to_node]\n",
        "            elif from_node == source_node and 0 <= to_node < num_jobs: inter_travel_time = 0\n",
        "            elif 0 <= from_node < num_jobs and to_node == sink_node: inter_travel_time = 0\n",
        "            elif from_node == source_node and to_node == sink_node: inter_travel_time = 0\n",
        "            else: return INF_TIME\n",
        "            origin_job_duration = 0\n",
        "            if 0 <= from_node < num_jobs: origin_job_duration = job_durations_min[from_node]\n",
        "            total_time = int(round(inter_travel_time + origin_job_duration))\n",
        "            return min(total_time, INF_TIME)\n",
        "        except IndexError: return INF_TIME\n",
        "        except Exception: return INF_TIME\n",
        "    transit_callback_index = routing.RegisterTransitCallback(time_callback)\n",
        "    routing.SetArcCostEvaluatorOfAllVehicles(transit_callback_index)\n",
        "    print(\"Callback de tiempo registrado y costo de arcos establecido.\")\n",
        "\n",
        "    # 9. Dimensi√≥n de Tiempo (igual que antes, con debug de SetRange)\n",
        "    print(\"A√±adiendo dimensi√≥n de Tiempo...\"); time_dimension_name = \"Time\"\n",
        "    max_route_time_min = PARAM_MAX_HORAS_POR_MOVIL * 60\n",
        "    max_window_end = max(w[1] for w in pickup_windows_min) if pickup_windows_min else 0\n",
        "    horizon = max(max_window_end + max(job_durations_min) if job_durations_min else 0, max_route_time_min); horizon += max_route_time_min\n",
        "    print(f\"  Horizonte: {horizon} min, Capacidad Ruta: {max_route_time_min} min, Slack: {MAX_SLACK_MINUTES} min\")\n",
        "    routing.AddDimension(transit_callback_index, MAX_SLACK_MINUTES, max_route_time_min, False, time_dimension_name)\n",
        "    time_dimension = routing.GetDimensionOrDie(time_dimension_name); print(f\"Dimensi√≥n '{time_dimension_name}' a√±adida.\")\n",
        "    print(\"Aplicando ventanas de tiempo a los trabajos...\");\n",
        "    try:\n",
        "        for job_idx in range(num_jobs):\n",
        "            index = manager.NodeToIndex(job_idx); start_win, end_win = pickup_windows_min[job_idx]\n",
        "            job_id_display = tasks[job_idx].get(ID_COLUMN_NAME, job_idx)\n",
        "            # print(f\"DEBUG: SetRange Job {job_id_display} [{start_win}, {end_win}]\") # Descomentar para debug detallado\n",
        "            if start_win > end_win: raise ValueError(f\"Ventana inv√°lida para Job {job_id_display}: [{start_win}, {end_win}]\")\n",
        "            time_dimension.CumulVar(index).SetRange(start_win, end_win)\n",
        "        source_index = manager.NodeToIndex(source_node)\n",
        "        # print(f\"DEBUG: SetRange Source [0, {horizon}]\") # Descomentar para debug detallado\n",
        "        time_dimension.CumulVar(source_index).SetRange(0, horizon)\n",
        "        print(\"Ventanas de tiempo aplicadas.\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\n!!! ERROR CR√çTICO al aplicar ventana de tiempo para Job {job_id_display} [{start_win}, {end_win}]: {e} !!!\"); return\n",
        "\n",
        "    # 10. Dimensi√≥n de Conteo de Trabajos (igual que antes)\n",
        "    print(f\"A√±adiendo dimensi√≥n de Conteo de Trabajos (max: {PARAM_MAX_RESERVAS_POR_MOVIL})...\")\n",
        "    jobs_dimension_name = \"Jobs\";\n",
        "    try:\n",
        "        def demand_callback(from_index):\n",
        "            from_node = manager.IndexToNode(from_index); return 1 if 0 <= from_node < num_jobs else 0\n",
        "        demand_callback_index = routing.RegisterUnaryTransitCallback(demand_callback)\n",
        "        routing.AddDimensionWithVehicleCapacity(demand_callback_index, 0, [PARAM_MAX_RESERVAS_POR_MOVIL] * num_vehicles, True, jobs_dimension_name)\n",
        "        print(f\"Dimensi√≥n '{jobs_dimension_name}' a√±adida.\")\n",
        "    except Exception as e: print(f\"Error a√±adiendo dimensi√≥n '{jobs_dimension_name}': {e}\")\n",
        "\n",
        "    # 11. Configurar B√∫squeda y Resolver (igual que antes)\n",
        "    print(\"Configurando par√°metros de b√∫squeda y resolviendo...\")\n",
        "    search_parameters = pywrapcp.DefaultRoutingSearchParameters()\n",
        "    search_parameters.first_solution_strategy = routing_enums_pb2.FirstSolutionStrategy.AUTOMATIC\n",
        "    search_parameters.local_search_metaheuristic = routing_enums_pb2.LocalSearchMetaheuristic.GUIDED_LOCAL_SEARCH\n",
        "    search_parameters.time_limit.seconds = SOLVER_TIME_LIMIT_SECONDS\n",
        "    search_parameters.log_search = True\n",
        "    print(f\"L√≠mite de tiempo del solver: {SOLVER_TIME_LIMIT_SECONDS} segundos.\")\n",
        "    solution = routing.SolveWithParameters(search_parameters)\n",
        "\n",
        "    # 12. Procesar Soluci√≥n, Exportar y Mostrar Resumen\n",
        "    if solution:\n",
        "        print(\"\\n********************* Soluci√≥n Encontrada! *********************\")\n",
        "        # --- Procesar la soluci√≥n para obtener datos estructurados ---\n",
        "        solution_routes, assigned_job_node_indices, total_jobs_assigned = process_and_print_solution(\n",
        "            num_jobs, tasks, {\"num_vehicles\": num_vehicles, \"source_node\": source_node, \"sink_node\": sink_node},\n",
        "            manager, routing, solution\n",
        "        )\n",
        "\n",
        "        # --- Crear lista de trabajos asignados para df_rutas ---\n",
        "        rutas_asignadas_list = []\n",
        "        vehicle_map = {} # Mapea ID interno de OR-Tools a ID secuencial 1..N\n",
        "        next_movil_id = 1\n",
        "        for route in solution_routes:\n",
        "            or_tools_vehicle_id = route['or_tools_vehicle_id']\n",
        "            if or_tools_vehicle_id not in vehicle_map:\n",
        "                vehicle_map[or_tools_vehicle_id] = next_movil_id\n",
        "                current_movil_id = next_movil_id\n",
        "                next_movil_id += 1\n",
        "            else:\n",
        "                current_movil_id = vehicle_map[or_tools_vehicle_id]\n",
        "\n",
        "            # A√±adir cada detalle de trabajo con el movil_id correcto\n",
        "            for job_detail in route['route_details']:\n",
        "                job_detail_export = job_detail.copy()\n",
        "                job_detail_export['movil_id'] = current_movil_id\n",
        "                # Eliminar claves internas si no se desean en el CSV\n",
        "                # del job_detail_export['or_tools_vehicle_id']\n",
        "                # del job_detail_export['node_index']\n",
        "                rutas_asignadas_list.append(job_detail_export)\n",
        "\n",
        "        df_rutas = pd.DataFrame(rutas_asignadas_list)\n",
        "        print(f\"\\nDataFrame 'df_rutas' creado con {len(df_rutas)} filas.\")\n",
        "\n",
        "        # --- Crear lista de trabajos NO asignados ---\n",
        "        reservas_no_asignadas_list = []\n",
        "        for job_idx in range(num_jobs):\n",
        "            if job_idx not in assigned_job_node_indices:\n",
        "                unassigned_task = tasks[job_idx].copy()\n",
        "                # A√±adir motivo (simplificado para OR-Tools)\n",
        "                unassigned_task['motivo_no_asignado'] = \"No incluido en soluci√≥n OR-Tools\"\n",
        "                reservas_no_asignadas_list.append(unassigned_task)\n",
        "\n",
        "        df_no_asignadas = pd.DataFrame(reservas_no_asignadas_list)\n",
        "        print(f\"DataFrame 'df_no_asignadas' creado con {len(df_no_asignadas)} filas.\")\n",
        "\n",
        "        # --- Exportar a CSV ---\n",
        "        rutas_csv_path = \"rutas_asignadas_ortools.csv\"\n",
        "        no_asignadas_csv_path = \"reservas_no_asignadas_ortools.csv\"\n",
        "        try:\n",
        "            df_rutas.to_csv(rutas_csv_path, index=False)\n",
        "            print(f\"Resultados de rutas asignadas exportados a: {rutas_csv_path}\")\n",
        "            df_no_asignadas.to_csv(no_asignadas_csv_path, index=False)\n",
        "            print(f\"Resultados de reservas no asignadas exportados a: {no_asignadas_csv_path}\")\n",
        "\n",
        "            # --- Descargar en Google Colab (si aplica) ---\n",
        "            if IN_COLAB:\n",
        "                print(\"Iniciando descarga de archivos en Colab...\")\n",
        "                files.download(rutas_csv_path)\n",
        "                files.download(no_asignadas_csv_path)\n",
        "            # --------------------------------------------\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\nError al exportar archivos CSV: {e}\")\n",
        "\n",
        "        # --- Imprimir Resumen Final ---\n",
        "        print(\"\\n--- Resumen Final ---\")\n",
        "        num_vehicles_used = len(solution_routes) # N√∫mero de veh√≠culos con ruta asignada\n",
        "        total_payment_assigned = df_rutas['estimated_payment'].sum() if 'estimated_payment' in df_rutas.columns else 0\n",
        "\n",
        "        print(f\"‚úÖ M√≥viles usados: {num_vehicles_used}\")\n",
        "        print(f\"‚úÖ Trabajos asignados: {total_jobs_assigned}\")\n",
        "        print(f\"üö´ Trabajos NO asignados: {len(df_no_asignadas)}\")\n",
        "        # Formatear el pago total como moneda\n",
        "        try:\n",
        "             print(f\"üí∞ Ganancia total estimada (asignados): ${total_payment_assigned:,.0f}\")\n",
        "        except ValueError:\n",
        "             print(f\"üí∞ Ganancia total estimada (asignados): {total_payment_assigned}\") # Sin formato si falla\n",
        "\n",
        "        print(\"**********************************************************\\n\")\n",
        "\n",
        "    else:\n",
        "        # --- Si no se encontr√≥ soluci√≥n ---\n",
        "        print(\"\\n******************** No se encontr√≥ soluci√≥n ********************\")\n",
        "        print(\"  No se generaron archivos de resultados.\")\n",
        "        print(\"  Posibles causas: Restricciones muy estrictas, datos inconsistentes,\")\n",
        "        print(\"                   l√≠mite de tiempo insuficiente, no hay suficientes veh√≠culos.\")\n",
        "        print(\"**********************************************************\\n\")\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Parte 5: Bloque de Ejecuci√≥n Principal\n",
        "# ----------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "      # --- CONFIGURAR RUTAS A ARCHIVOS ---\n",
        "      hist_file = '/content/distancias H3 2.0 (Hist).csv'        # ¬°¬°¬° CAMBIA ESTO !!!\n",
        "      pred_file = '/content/distancias H3 2.0 (Pred) - 25-04 05-15.csv'    # ¬°¬°¬° CAMBIA ESTO !!!\n",
        "      # ------------------------------------\n",
        "\n",
        "      print(f\"Iniciando proceso de optimizaci√≥n de rutas...\")\n",
        "      print(f\"Archivo hist√≥rico: {hist_file}\")\n",
        "      print(f\"Archivo de predicciones: {pred_file}\")\n",
        "      print(f\"ID Column Name expected in predictions: '{ID_COLUMN_NAME}'\")\n",
        "\n",
        "      if not os.path.exists(hist_file):\n",
        "          print(f\"\\nERROR FATAL: El archivo hist√≥rico '{hist_file}' no existe.\")\n",
        "      elif not os.path.exists(pred_file):\n",
        "          print(f\"\\nERROR FATAL: El archivo de predicciones '{pred_file}' no existe.\")\n",
        "      else:\n",
        "          main_ortools(hist_file, pred_file)\n",
        "\n",
        "      print(\"Proceso finalizado.\")"
      ],
      "metadata": {
        "id": "IE73nbKM4Dkp",
        "outputId": "b267e45c-a8af-447c-bfff-7f5097b15b11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "IE73nbKM4Dkp",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando proceso de optimizaci√≥n de rutas...\n",
            "Archivo hist√≥rico: /content/distancias H3 2.0 (Hist).csv\n",
            "Archivo de predicciones: /content/distancias H3 2.0 (Pred) - 25-04 05-15.csv\n",
            "ID Column Name expected in predictions: 'job_id'\n",
            "Cargando archivos...\n",
            "Hist√≥ricos cargados: 461962 filas\n",
            "Predicciones cargadas: 215 filas\n",
            "Validando y preparando datos de predicci√≥n...\n",
            "Horizonte de planificaci√≥n inicia en: 2025-04-25 05:00:00\n",
            "Precalculando promedios hist√≥ricos...\n",
            "Limpiando datos hist√≥ricos...\n",
            "  85796 filas eliminadas por NaNs o tiempo inv√°lido.\n",
            "Calculando H3 y distancias para datos hist√≥ricos...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-384875a72c93>:82: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_hist['tiempoestimada'] = pd.to_numeric(df_hist['tiempoestimada'], errors='coerce')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  7 filas eliminadas por c√°lculo inv√°lido de H3/distancia.\n",
            "Calculando tiempos promedio agrupados por H3...\n",
            "Se calcularon promedios hist√≥ricos (mediana). 79205 pares H3 origen-destino encontrados.\n",
            "Calculando velocidad promedio global (fallback)...\n",
            "Velocidad promedio (mediana) calculada (fallback): 36.10 km/h\n",
            "Preparando lista de tareas (trabajos)...\n",
            "N√∫mero de trabajos a asignar: 215 (se saltaron 0)\n",
            "N√∫mero de veh√≠culos a usar: 100\n",
            "Precalculando matriz de tiempos de viaje inter-trabajos...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando Matriz Tiempos: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 215/215 [17:24<00:00,  4.86s/job]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriz de tiempos inter-trabajos calculada.\n",
            "Configurando modelo OR-Tools...\n",
            "Manager y Modelo creados.\n",
            "Callback de tiempo registrado y costo de arcos establecido.\n",
            "A√±adiendo dimensi√≥n de Tiempo...\n",
            "  Horizonte: 1537 min, Capacidad Ruta: 600 min, Slack: 30 min\n",
            "Dimensi√≥n 'Time' a√±adida.\n",
            "Aplicando ventanas de tiempo a los trabajos...\n",
            "\n",
            "!!! ERROR CR√çTICO al aplicar ventana de tiempo para Job 23673492 [620, 680]: CP Solver fail !!!\n",
            "Proceso finalizado.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}